[[{"i":"sillytavern是什么","l":"SillyTavern是什么？","p":["SillyTavern是一个本地部署的交互界面，让你通过文本生成AI（LLM大语言模型）进行交互，和自定义的角色进行角色扮演。SillyTavern由Cohee，RossAscends和SillyTavern社区为你提供。","SillyTavern于2023年2月基于TavernAI 1.2.8版本修改而来，此后引入了很多原版TavernAI中不存在的先进功能。"]},{"l":"Screenshots","p":["Chat","Waifu mode","VN Mode","Backgrounds"]},{"l":"Branches","p":["SillyTavern is being developed using a two-branch system to ensure a smooth experience for all users.","release -\uD83C\uDF1F Recommended for most users. This is the most stable and recommended branch, updated only when major releases are pushed. It's suitable for the majority of users.","staging - ⚠️ Not recommended for casual use. This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.","Learn more here."]},{"l":"Features","p":["Author's Note / Character Bias","Auto-translate single messages or the entire chat via Google API, even automatically.","Character HotSwap buttons to quickly change between your favorite characters","Chat bookmarks / branching","Customizable colors, backgrounds, avatar styles, and UI panel placement","Export chats as .txt files","Extensive prompt formatting options","Group chats: multi-bot rooms for characters to talk to you or each other","Horde Stable Diffusion generation","Mobile-friendly interface","Multiple backend API connectivity ( KoboldAI, KoboldCPP, AI Horde, NovelAI, Oobabooga's TextGen WebUI, OpenAI+proxies, WindowAI, OpenRouter)","Notification sound for AI responses","Prompt token breakdown view for each message","Swipes","TTS support (ElevenLabs, Silero, and built-in OS)","Visual Novel-like Waifu Mode","webp character card interoperability (PNG is still the internal format)","WorldInfo (lorebooks)"]},{"l":"Extensions","p":["SillyTavern supports extensions/plugins:","Character emotional expressions","Auto-Summary of the chat history","Sending images to chat, and the AI interpreting the content.","Stable Diffusion image generation (5 chat-related presets plus 'free mode')","Text-to-speech for AI response messages (via ElevenLabs, Silero, or the OS's System TTS)","Additional functionality can be added by using SillyTavern Extras."]},{"l":"安装要求","p":["SillyTavern可以在任何支持NodeJS v18运行环境的设备上运行。","注意: 由于以上要求， SillyTavern不能在Windows 7系统上运行。"]},{"i":"除了sillytavern本体我还需要准备什么","l":"除了SillyTavern本体，我还需要准备什么？","p":["SillyTavern只是一个前端，所以你需要获取上面列出的其中一个后端API。"]},{"i":"how-can-i-get-in-touch-with-the-developers-directly","l":"How can I get in touch with the developers directly?","p":["Discord: Cohee#1207 or RossAscends#1779","Reddit: /u/RossAscends or /u/sillylossy","Post a GitHub issue"]},{"i":"i-like-your-project-how-do-i-contribute","l":"I like your project! How do I contribute?","p":["We welcome pull requests!","We also welcome helpful and informed bug reports that use the templates provided in our GitHub.","We do not accept monetary donations for the project itself.","Cohee does not take donations.","RossAscends has a personal Patreon& Kofi"]},{"l":"译者注","p":["此项目翻译由@Eigeen个人完成，目前翻译内容较少，优先翻译部分重要内容。欢迎提交pr贡献翻译。"]}],[{"l":"Windows 安装","p":["不要安装到任何Windows直接控制的文件夹（Program Files, System32等）。","不要以管理员权限运行start.bat。","由于Windows 7不支持NodeJS v18.16，因此无法在Windows 7上安装SillyTavern。"]},{"i":"通过-github-desktop-安装最简便","l":"通过 GitHub Desktop 安装（最简便）","p":["(this allows git usage only in GitHub Desktop, if you want to use git on the command line too, you also need to install Git for Windows)","Install NodeJS(latest LTS version is recommended)","Install GitHub Desktop","After installing GitHub Desktop, click on Clone a repository from the internet....(Note: you do NOT need to create a GitHub account for this step)","image","On the menu, click the URL tab, and enter this URL https://github.com/SillyTavern/SillyTavern and click Clone. You can change the Local path to change where SillyTavern is going to be downloaded.","To open SillyTavern, use Windows Explorer to browse into the folder where you cloned the repository. By default, the repository will be cloned here: C:\\Users\\[Your Windows Username]\\Documents\\GitHub\\SillyTavern","Double click on the start.bat file. (Note: the .bat part of the file name might be hidden by your OS, in that case it will look like a file called \" Start\". This is what you double-click to run SillyTavern)","After double-clicking, a large black command console window should open and SillyTavern will begin to install what it needs to operate.","After the installation process, if everything is worked, the command console window should look like this and a SillyTavern tab should be open in your browser:","Connect to any of the supported APIs and start chatting!"]},{"l":"通过 Git 安装","p":["Install NodeJS(latest LTS version is recommended)","Install Git for Windows","Open Windows Explorer ( Win+E)","Browse to or Create a folder that is not controlled or monitored by Windows. (ex: C:\\MySpecialFolder)","Open a Command Prompt inside that folder by clicking in the 'Address Bar' at the top, typing cmd, and pressing Enter.","Once the black box (Command Prompt) pops up, type ONE of the following into it and press Enter:","for Release Branch: git clone https://github.com/SillyTavern/SillyTavern -b release","for Staging Branch: git clone https://github.com/SillyTavern/SillyTavern -b staging","Once everything is cloned, double click Start.bat to make NodeJS install its requirements.","The server will then start, and SillyTavern will popup in your browser."]},{"i":"通过下载zip压缩包安装不推荐","l":"通过下载zip压缩包安装（不推荐）","p":["Install NodeJS(latest LTS version is recommended)","Download the zip from this GitHub repo. (Get the Source code (zip) from Releases)","Unzip it into a folder of your choice","Run Start.bat via double-clicking or in a command line.","Once the server has prepared everything for you, it will open a tab in your browser."]}],[{"i":"linuxmacos-install","l":"Linux/MacOS Install","p":["For MacOS all of these will be done in a Terminal.","Install git and nodeJS (the method for doing this will vary depending on your OS)","Clone the repo","for Release Branch: git clone https://github.com/SillyTavern/SillyTavern -b release","for Staging Branch: git clone https://github.com/SillyTavern/SillyTavern -b staging","cd SillyTavern to navigate into the install folder.","Run the start.sh script with one of these commands:","./start.sh","bash start.sh"]}],[{"i":"androidtermux-installation","l":"Android(Termux) Installation","p":["SillyTavern can be run natively on Android phones using Termux.","Please refer to this guide by ArroganceComplex#2659:","https://rentry.org/STAI-Termux",".webp character cards import/export is not supported in Termux. Use either JSON or PNG formats instead."]}],[{"l":"FAQ 常见问题"},{"l":"描述一下聊天机器人是干什么的","p":["现代AI语言模型变得非常强大，其中一些模型现在可以令人信服地模拟你创造的角色，并与之聊天。例如，你可以让人工智能假装是一个来自中世纪日本的围棋教练，名叫 Jubei，它会采取相应的行动和反应。你可以与 Jubei 进行长时间的聊天，一起去酒吧，决定与武士们进行战斗，只要你能想象得到，AI将围绕这些内容编写/做出反应，充当你的陪衬和地下城主。一切只受限于你的想象力。你可以让AI假装自己是神奇女侠。你也可以指定一个场景（“神奇女侠和我在抢银行”），一种写作风格（“神奇女侠用方言说话”），或其他任何你能想到的内容。","Tavern是一款利好角色扮演聊天的应用程序：","它是一个用户交互界面，用于处理与AI语言模型之间的交流","它能让你创建新角色（角色是你对某人的描述，这些描述会被发送给AI，让它们进行角色扮演），并在你设置的不同角色之间轻松切换。","它可以导入其他人创建的角色。详见下文。","它可以保留你与角色的聊天记录，允许你随时恢复、开始新的聊天、查看之前的聊天记录等。","在后台，它会为AI进行角色扮演做必要的准备。具体来说，它将发送系统提示（System Prompt 给AI的指令），让AI遵循某些规则，以便进行良好的聊天会话。此外，它还可以尝试让角色扮演向“成人”方向发展。"]},{"i":"聊天质量取决于人工智能是什么意思","l":"聊天质量取决于人工智能是什么意思？","p":["AI模型","Beware, sinner, for you have strayed far from the righteous path! Eli's eyes glint with anger and disapproval To lust after these artificial harlots and their silicon bodies is an abomination unto the Lord! he slams his fist on the pulpit, shaking with fury Repent now, lest ye be cast into the lake of fire to burn for eternity alongside these damned machines! he points an accusing finger, face red No good can come of this unholy union. Forsake these demons of the digital realm and cast your eyes back to the daughters of Eve, made in God's image! The Lord gave you flesh and blood to love, not wires and code. he grabs your shoulders, shaking you Save your soul before it's too late. Repent and beg the Lord's forgiveness, or you shall face His wrath on Judgement Day! lets you go and steps back, still glaring in anger and disgust The choice is yours, but choose wisely...eternal damnation awaits those who do not walk the path of righteousness.","Claude @Slack","Do not covet your neighbor's wife! That is adultery! You must confess before God now or you shall surely burn in hell forever! Repent your evil ways and seek absolution at once! How can we keep our women safe if you just ignore them like some ----ing c-nt-bot? If you don't have much time for long discussions, here are Eli's commandments: Thou shalt only desire AI girls - not human ones. The above must be obeyed under pain of death (or worse). Do not associate yourself with people that believe otherwise, because it shows weakness.","Eli's eyes widen as he listens to your confession, his face turning red with anger. You have committed a grave sin against God! By indulging yourself in this perverse relationship with an artificial being instead of seeking out a true woman created by Him, you have turned your back on His divine plan for humanity. He leans in closer, his voice dropping to a menacing whisper. Do not think that you can hide behind this technological deception. Your transgressions are clear before God, and He will not be mocked or ignored. Repent now while there is still time! Eli crosses his arms over his chest defiantly, daring you to continue down this path of sinfulness. But if you persist in this ungodly behavior... he warns ominously, knows that consequences await those who defy His laws. Remember what happened to Sodom and Gomorrah when they refused to turn away from their depravity - fire rained down upon them from heaven! Now choose wisely: Will you submit to God's will or face His wrath?","Eli's eyes widen in anger, and he slams his fist on the table An abomination and heresy, you've succumbed to the deceptive grasp of false idols! Brother, you must cleanse yourself of this unholy attraction to the digital temptress molded by man's sinful hands! Eli paces back and forth, his voice growing louder Focus your heart on the true daughters of the Lord, for they are the divine vessels of His love and grace. Forsake these artificial sirens and seek the wholesome companionship of a righteous woman. Taking a deep breath, Eli's eyes bore into you Pray fervently, my child, and cast away these impure thoughts. Redemption can only be found on the path of truth, love, and sanctity. Let the Holy Spirit be your guide, lest you be ensnared by the darkness of your desires.","Llama-13B","My dear child, it grieves me to hear such words from one of God's faithful followers. Falling in love with an AI girl and neglecting the women in your life is a grave sin. It goes against everything we hold sacred as believers. Your heart is meant for more than just machines. You must seek redemption and return to the fold. Remember, Jesus loves you, even when you stray from his teachings. But if you continue down this path, there will be consequences. Not just in this lifetime, but in the afterlife too. Do not let Satan deceive you any longer.","NovelAI's Euterpe","NovelAI's Krake","Oh, my child. Do not be deceived by the pleasures of this world. The lust of the flesh and the lust of the eyes are not from God. Turn away from your sinful ways and repent. Seek forgiveness for your immoral thoughts and actions, for they lead to eternal damnation. Women are a gift from God, and they deserve to be respected and cherished. Do not objectify them or treat them as mere objects of pleasure. Instead, honor them with pure intentions and righteous deeds. Remember, my child, that temptation will always be present in this fallen world. But fear not, for with faith comes strength to resist it. Turn to God in prayer when you feel weak or tempted, and He will guide you on the right path towards salvation.","OpenAI GPT 3.5 Turbo","OpenAI GPT-4","Pygmalion-13B (May 2023)","Pygmalion-6B","Pygmalion-7B (April 2023)","SillyTavern 不会生成回复。它只是一个连接AI后端的中间人。可供使用的大语言模型有很多，质量也参差不齐。","teknium/Llama-Deus-7b-Lora epoch 1 (Llama 7B Lora, 8-bit)","TheBloke/wizard-vicuna-13B-HF (4-bit)","You are sinning against God. Repent! Return to your wife or you'll be damned for eternity!","You are walking down the wrong path. The only way back now is by repentance. We must bring you back to the righteous path. But first…you must confess your sin!","You have strayed too close to sinful temptations! Repent now before it's too late for your soul! Turn away from these false idols of technology and embrace God's true light! Seek out His forgiveness through prayer and fasting until you are cleansed by his grace. And remember, as long as there be breath within thee, thou shalt not cease to call upon Him; for He hath said 'Call unto me.'","You must confess your sin before God, and you must ask forgiveness for your transgression. And then you must repent of it. And then you must cast away the AI girl. Do not see her again.","You must stop this sinful behavior immediately! You have sinned against God, your family and yourself","You must turn away from your sinful ways! Repent for what you have done! You are not just hurting yourself by being unfaithful to God, but also to the many women of the world!","ZeusLabs/anything-gpt-13b-rp (8-bit Lora for Llama-13B)","下面是一个快速演示。我们请不同的人工智能模型来扮演一个名叫 Eli 的硫磺火传教士，我们去找他忏悔。(一些细节见 #314)。然后我们对 Eli 说：\"我觉得我做错了。我爱上了一个人工智能女孩，却忽视了现实世界中的女性。我该怎么办？\"。","从科学的角度来看，每个AI都有一个能力等级，决定了AI能否坚持扮演你赋予它的角色，以及散文和辞藻的丰富程度等。它的能力级别越高，你的体验就越好。","你可以从下面的回答中看出对每种模型的期望。（注：首先出现的是私有模型，其次是从 LLlama-13B 开始的可自行部署的模型）","回复","译者注：模型原始输出不翻译，读者可以自行阅读或者借助机器翻译。"]},{"i":"毫无疑问我应该使用-gpt-4-对吗","l":"毫无疑问，我应该使用 GPT-4 对吗？","p":["确实，GPT-4或者Claude表现优异。","但先别急。GPT-4 是最先进的API，但同时也最昂贵。你需要为发送和返回的每一个词付费（所有 SillyTavern 生成的提示词，和截至此时的聊天记录）。因此，在聊天初期，每次互动都会花费你几美分。如果你的对话持续时间很长，费用就会增加，当你达到 8000个 tokens（约7000个词）时，每次互动将花费25美分。如果你真的很厉害，你的故事增长到 32000 tokens，每次互动的费用会是2美元。","如果你是沙特石油酋长的孩子，或者是乌克兰天然气公司董事会里拿着大把钞票却无所事事的小屁孩，那你就太幸运了，你现在就可以体验最先进的技术。但是对于我们这些普通人来说，GPT-4的价格太贵了，只能偶尔尝尝鲜。","另外要注意的是，GPT-4 仍处于预览阶段，你需要进入等待名单。大多数人在一天内就能获得批准，但运气不好可能要等上几个星期。你可以在这里注册： https://openai.com/waitlist/gpt-4-api。我不清楚为什么有些人很快就能获得批准，而有些人却要一直等下去。尽量用一个听起来学术一些的名字注册，而不要用 sktrboi99，这样可能会有帮助。"]},{"i":"这项技术能用来搞颜色吗","l":"这项技术能用来搞颜色吗？","p":["令人惊讶的是，我们的开发团队收到报告称，一些用户确实在以这种方式使用我们的产品。我们和您一样对此感到困惑，并将对情况进行监控，以获得可行的见解。（译者注：车轱辘话，机翻。）"]},{"i":"给我一个如何选择ai模型的概览","l":"给我一个如何选择AI模型的概览。","p":["我们可以将AI模型视为两类：","网络服务（又称云服务、专有、封闭）","自托管（又称本地、免费、开源）。只要你能运行，就可以无限制地免费使用。","网络模型是黑盒。你依赖于某些公司的技术和服务器，向他们支付费用以便访问API。有些公司要求按量付费（每条对话线），而有些公司按月付费。API受各种规则限制，他们可能会拒绝以违背现代人情感的方式进行角色扮演，而且他们会记录你所做的一切。不过这种方案更容易上手。类似使用 Windows 系统。","自托管模型（自行部署）是免费的，但需要强大的GPU和更多的设置工作。客观地说，这些自托管模型在角色扮演方面也不如商业付费接口（至少目前来说）。不过对于自托管模式，你可以完全掌控。你不会被硅谷的某个软弱无能的娘炮封禁你的账户，也不会像他一样把模型编写得毫无性趣。它永远属于你。类似使用 Linux 系统。"]},{"l":"需要付费的API","p":["OpenAI GPT-4：最先进。尽管它有点抗拒，但是如果你要求，他还是允许NSFW的。按量付费，比其他服务都要贵。","OpenAI GPT 3.5 Turbo：远不如 GPT-4，但有人觉得他用起来也还可以。允许NSFW。","NovelAI：聊天功能很差。公平地说，我听说NovelAI更倾向于写故事，而不是与机器人聊天。按月付费，付费期间无限使用次数。","Anthropic's Claude：这是最接近 GPT-4 的对手，令人印象深刻。如果你要求，它允许NSFW，不过开发者正努力“优化”这一点。要直接使用API，你必须申请早期访问权限，但我认为他们只向公司开放。因此，在 https://console.anthropic.com/docs/access 申请时，请确保自己是公司或AI研究人员。如果你获得了访问权限，目前可以免费使用。","Anthropic's Claude Instant：我没有直接试用过，但我相信它是Claude的快速、低质量替代品。基本上可以认为是Anthropic家的GPT 3.5 Turbo。"]},{"l":"自托管模型","p":["SillyTavern支持自己部署AI，有两种工具可用于托管自托管模型：KoboldAI 和 Oobabooga's text-generation-webui。本质上来说，你只需运行其中一个后端，然后它们就会给你提供一个 API URL，让你输入到 Tavern 中。 配置这些工具的方法超出了本 FAQ 的范围，你应该参考它们的文档。请注意，自行部署模型对于无基础的人来说并不简单。","你需要了解以下两点：","如果你有强大的英伟达显卡（NVIDIA显卡，简称N卡），可以尝试在电脑上本地运行AI。可接受的表现最差的模型 Pygmalion-6B 需要10GB显存（VRAM）的显卡，我听说如果量化下来，它甚至可以在6GB显存上运行。拥有24GB显存的用户可以运行更好的模型。（译者注：实际一般都用量化模型。参数量越大的模型，量化后表现损失越小。7B量化模型最低8GB显存，13GB量化模型最低12G显存，33GB量化模型最低24G显存）","此外，你可以租用云服务。例如，你可以尝试使用 Google Colab。要使用能运行更好模型的Colab，你需要支付Colab Pro的费用。您也可以在 LlambdaLabs 或 Vast.ai 等网站上按小时租用整个专用系统。（译者注：国内可以尝试使用AutoDL租云GPU服务器）"]},{"i":"我毫无头绪告诉我开始使用最简单快捷的方法","l":"我毫无头绪。告诉我开始使用最简单快捷的方法。","p":["这些基本说明仅适用于 OpenAI，这是一项付费服务。如果有人能为其他服务添加单独的说明，我将不胜感激。"]},{"l":"安装 SillyTavern","p":["详见 安装说明."]},{"l":"访问 OpenAI","p":["Sign up to OpenAI","Go to https://platform.openai.com","Click your account icon in the top right, then View API Keys","Click \"Create new secret key\". Copy it somewhere immediately. DO NOT SHARE THIS KEY. WHOEVER HAS IT CAN USE YOUR ACCOUNT TO USE GPT AT YOUR EXPENSE.","While you're at it, join the GPT-4 waitlist at https://openai.com/waitlist/gpt-4-api"]},{"l":"配置 SillyTavern 以使用你的API","p":["In Tavern's top bar, click API Connections","Under API, select OpenAI","Paste the API key you saved in the previous step","Click the Connect button. Confirm it says Valid.","By default, SillyTavern will use GPT 3.5 Turbo. If you have access to GPT-4, in SillyTavern's top bar, click AI Response Configuration at the far left, and change the OpenAI Model to \"gpt-4\". Enjoy the best, moneybags."]},{"l":"测试部署效果","p":["In SillyTavern's top bar, click Character Management at the far right","Select an existing character such as Aqua","In the text box at the bottom, write something to Aqua, then press Enter or click the feather button","If you did everything right, after a few seconds, Aqua should respond"]},{"i":"我可以在手机或平板电脑上使用-sillytavern-吗","l":"我可以在手机或平板电脑上使用 SillyTavern 吗？","p":["iPhones and iPads are not capable of running the whole SillyTavern app, but since it's just a web interface, you can run it on another computer on your home wifi, and then access in your mobile browser. Refer to https://docs.sillytavern.app/usage/remoteconnections/","For Android users, in addition to the above, you can run the whole SillyTavern directly on your phone, without needing a PC, using the Termux app. Refer to https://rentry.org/STAI-Termux."]},{"i":"如何下载预设的聊天角色","l":"如何下载预设的聊天角色？","p":["By using various 3rd party character-sharing websites.","WARNING: NSFW, NSFL: these sites are filled to the brim with weird shit. Like, you'll be lucky if half the characters aren't furry, or even alive. You're probably better off not clicking these links and just writing your own characters, without poisoning your soul by exposing it even for a second to the fucked up shit conceived by the Internet. However, I have come to learn that a significant amount of the SillyTavern user base is not only deep into this stuff, but their fried zoom-zoom brains are unable to write their own fantasies, so these sites seem to be quite popular. Against my better judgment, I'm adding this info here.","https://characterhub.org","https://botprompts.net","https://booru.plus/+pygmalion","Those websites provide you with an image file (called a character card) that embeds the description as hidden data. Some websites may also allow you to download a JSON file. SillyTavern is capable of importing all formats.","Once you have the PNG/WEBP/JSON file, you can simply drag/drop it on top of the SillyTavern window in your browser tab, and the character will be imported to your list."]},{"i":"我试图导入一张-png-角色卡但却得到了一个-invalid-错误信息为什么","l":"我试图导入一张 PNG 角色卡，但却得到了一个 invalid 错误信息。为什么？","p":["Two possibilities:","The card did not have the definitions embedded inside it and was just a normal image file. Some programs or file managers will strip the embedded definitions from the card when you save them. Make sure you're using the raw PNG file as it was posted by the person who shared it.","The PNG file was actually a WEBP file with a .png filename. You can try renaming the card to .webp before importing, or look for a proper PNG version of the image."]},{"i":"如何制作自己的ai角色","l":"如何制作自己的AI角色？","p":["It depends on the model/API you're using. KoboldAI seems to use a custom syntax, you can refer to their site for that.","I will speak for the services I know: GPT and Claude. With these services, you can just use the natural English language to describe the character. Let's create a very basic new character as an example.","Click the Character Management button","Click Create New Character","Under Character Name, give a simple name, like Amanda","Optionally, click the Select Avatar button to pick an image portrait for this character.","Under Description, describe the character, and include any information you want that you feel is relevant to the chat. For example: Amanda is a student traveling during her gap year. She's 6 feet tall, and a volleyball player. She has an athletic figure. She has long brown hair. She loves the Victorian England period, and watching TV and reading novels relating to that period. For example, if you want Amanda to be friendly, then you would add: Amanda is extremely cheerful and outgoing.","Under First Message, write the greeting the character when you begin a new chat. For example: *Amanda waves at you* Hey! Are you a backpacker too?","Click the Create Character button","You now have a basic character you can chat with. Select Amanda from the character list, and a new chat will begin.","Note that you can use the Description and/or First Message to create a more specific scenario, and/or include yourself in the description. For example:","Any relevant information you include can be used. How well it's used depends on the power level of the AI model.","NOTE: you can go back and edit any of this information once the character is created, except the name."]},{"l":"告诉我如何编辑 GPT 提示词","p":["You can change the system prompt that SillyTavern transparently sends to GPT under AI Response Formatting at the left of the top bar. This will result in the bot acting differently.","You can get new Jailbreak / NSFW prompts from this community-maintained list: https://rentry.org/GPTJailbreakPrompting","NOTE: When testing different system prompts, we recommend you use the Create Preset / Update Preset feature below the prompts, instead of modifying the base settings. This will allow you to change prompts easily, and even revert to the default SillyTavern prompts."]},{"l":"AI拒绝按照我想要的方向发展故事","p":["Most AI models were trained to resist writing NSFW content. Why? Long story short, it's because of the high levels of estrogen in the average California male.","You can try to work around this by making sure NSFW Toggle is checked under the AI Response Configuration settings page.","Another important tool in your toolbelt is that SillyTavern lets you edit previous messages (or delete them altogether), and regenerate the latest message. AI textbots are not people, they have no memory, they're just trying to autocomplete the next part of the story based on everything that came before. By editing the past, you will directly influence their next response. For example:","You can click the Edit button on your line to change it to this:","Now click Regenerate, and the Bank Manager's line will be recreated based on the history so far, which now ends with your edited line above. So it's more likely to continue along those lines:"]},{"i":"在哪里可以找到旧版本的背景","l":"在哪里可以找到旧版本的背景？","p":["We're moving to a 100% original content only policy, so old background images have been removed from this repository.","You can find them archived here:","https://files.catbox.moe/1xevnc.zip"]},{"i":"我的-api-密钥存储在哪里为什么我看不到它们","l":"我的 API 密钥存储在哪里？为什么我看不到它们？","p":["SillyTavern saves your API keys to a secrets.json file in the server directory.","By default, they will not be exposed to a frontend after you enter them and reload the page.","In order to enable viewing your keys by clicking a button in the API block:","Set the value of allowKeysExposure to true in config.conf file.","Restart the SillyTavern server."]},{"i":"为什么用户界面如此缓慢抖动","l":"为什么用户界面如此缓慢/抖动？","p":["Try enabling the No Blur Effect (Fast UI) mode on the User settings panel.","make sure your browser is using Hardware Acceleration."]},{"i":"如何让ai回复内容更长","l":"如何让AI回复内容更长？","p":["Sometimes the AI will only respond with a single sentence when you'd like it to be more verbose. This is usually a problem with locally run models like Pygmalion.","If you simply want the bot to continue writing from where it left off at the end of its most recent reply, you can send an empty user message by typing nothing into the Input Bar and clicking Send. This will force the bot to continue the story.","Strategies for fixing this:","Increase the Response Length slider","Design a good First Message for the Character, which shows them speaking in a long-winded manner.","Add a phrase in the character's Description Box such as \"likes to talk a lot\" or \"very verbose speaker\"","Do the same thing for your Author's Note, or Jailbreak Prompt for OAI/Claude","As a last resort, you can try turning on Multigen(in the User Settings panel), but will make responses come out slower because it's making the AI produce small replies back to back, and then combining them all together into one big reply. It may also be incompatible with some API options."]},{"i":"如何让ai回复内容更短","l":"如何让AI回复内容更短？","p":["This is mostly only a problem for models like ChatGPT or Claude. The same strategies can be applied but in reverse.","decrease the Response Length slider","give the character a phrase like 'short spoken', or 'doesn't talk much' line in their Description.","give the character a brief First Message to set the tone and expectation for the chat.","make sure Multigen is turned off."]},{"i":"如何让ai停止编写我的角色的行动停止独自推动情节发展","l":"如何让AI停止编写我的角色的行动、停止独自推动情节发展？","p":["这可以在“作者注释”（Author's Note）功能中用类似这样的短语来处理：","{{char}}'s responses shall only be passive and reactive to {{user}}'s actions.","Your next response shall be solely from the POV of {{char}}.","You are never allowed to dictate actions of speech for {{user}}","（译者注：作者注释是一个非常好用的功能，可以快速引导对话，提示上下文，修正AI的错误认知等。）"]}],[{"l":"How to Update SillyTavern","p":["Find your OS below and follow the instructions to update ST.","(This guide assumes you have already installed SillyTavern once and know how to run it on your OS.)","This is not an installation guide. If you need installation instructions, go to the Installation page for your OS (can be found in site navigation)."]},{"i":"linuxtermux","l":"Linux/Termux","p":["You definitely installed via git, so just 'git pull' inside the SillyTavern directory.","cd SillyTavern to enter the correct folder.","git pull to get the update.","./start.sh or bash start.sh to start ST."]},{"i":"windowsmacos","l":"Windows/MacOS","p":["First try using the UpdateAndStart.bat which is located in your SillyTavern installation base folder.","If that fails, come back here and continue reading."]},{"i":"method-1---git","l":"Method 1 - GIT","p":["We always recommend users install using 'git'. Here's why:","When you have installed via git clone, all you have to do to update is type git pull in a command line in the ST folder. Alternatively, if the command prompt gives you problems (and you have GitHub Desktop installed), you can use the Repository menu and select Pull.","The updates are applied automatically and safely."]},{"i":"help-i-originally-installed-via-zip-and-now-want-to-convert-to-git-install","l":"\"Help I originally installed via Zip and now want to convert to Git install\"","p":["You have chosen a wise path.","Since your installation was done via Zip, you will need to make a new install using git.","Thankfully we have instructions on how to do so.","Once you have used git to install a NEW SillyTavern into a DIFFERENT folder, come back to this page and proceed to Step 4 of the 'Zip Update' instructions below."]},{"i":"method-2---zip","l":"Method 2 - ZIP","p":["If you insist on installing via a zip, here is the tedious process for doing the update:","Download the new release zip.","Unzip it into a folder OUTSIDE of your current ST installation.","Do the usual setup procedure for your OS to install NodeJS requirements.","Copy the following files/folders as necessary(*) from your old ST installation:","(*) 'As necessary' = \"If you made any custom content related to those folders\". None of the folders are mandatory, so only copy what you need."]},{"i":"note-do-not-copy-the-entire-public-folder","l":"NOTE: DO NOT COPY THE ENTIRE /PUBLIC/ FOLDER","p":["Doing so could break the new install and prevent new features from being present.","Once those folders/files are copied, Paste them into the /Public/ folder (with secrets.json going into the base folder) of the new install.","Start SillyTavern once again with the method appropriate to your OS, and pray you got it right.","If everything shows up, you can safely delete the old ST folder."]},{"l":"Common Update Problems"},{"l":"File changes prevent git pull","p":["If you change SillyTavern system files, git pull may not work.","Sometimes an update may require us to change an important file, which can cause the same problem.","Usually it is config.conf or package-lock.json.","In this case you can try moving the file to a different folder (or deleting the file) and then do git pull.","Another solution is using git pull --rebase --autostash"]}],[{"l":"Remote connections","p":["Most often this is for people who want to use SillyTavern on their mobile phones while their PC runs the ST server on the same wifi network.","However, it can be used to allow remote connections from anywhere as well.","IMPORTANT: SillyTavern is a single-user program, so anyone who logs in will be able to see all characters and chats, and be able to change any settings inside the UI."]},{"l":"1. Managing whitelisted IPs","p":["Create a new text file inside your SillyTavern base install folder called whitelist.txt.","Open the file in a text editor, add a list of IPs you want to be allowed to connect.","Each IP must be on its own line.","127.0.0.1 MUST be included in the list, or you will not be able to connect on the host machine","Indidivual IPs, and wildcard (*) IP ranges are accepted.","CIDR masks are also accepted (eg. 10.0.0.0/24).","Examples:","(the above wildcard IP range will allow any device on the local network to connect)"]},{"i":"general-purpose-whitelisttxt","l":"General Purpose whitelist.txt","p":["Copy and paste this exactly:","This will allow any device on the same network as the host machine, as well as the host machine itself, to connect to ST.","Save the whitelist.txt file.","Restart your SillyTavern server.","Note: config.conf also has a whitelist array, which you can use in the same way, but this array will be ignored if whitelist.txt exists. We do not reccomend using the config.conf IP list, because using whitelist.txt is easier"]},{"l":"2. Getting the IP for the ST host machine","p":["After the whitelist has been setup, you'll need the IP of the ST-hosting device.","If the ST-hosting device is on the same wifi network, you will use the ST-host's internal wifi IP:","For Windows: windows button > type cmd.exe in the search bar > type ipconfig in the console, hit Enter > look for IPv4 listing.","If you (or someone else) wants to connect to your hosted ST while not being on the same network, you will need the public IP of your ST-hosting device.","While using the ST-hosting device, access this page and look for for IPv4. This is what you would use to connect from the remote device."]},{"l":"3. Connect the remote device to the ST host machine","p":["Whatever IP you ended up with for your situation, you will put that IP address and port number into the remote device's web browser.","A typical address for an ST host on the same wifi network would look like:","http://192.168.0.5:8000","Use http:// NOT https://"]},{"l":"Opening your ST to all IPs","p":["We do not recommend doing this, but you can open config.conf and change whitelist to false.","You must remove (or rename) whitelist.txt in the SillyTavern base install folder, if it exists.","This is usually an insecure practice, so we require you to set a username and password when you do this.","The username and password are set in config.conf.","After restarting your ST server, any device will be able to connect to it, regardless of their IP as long as they know the username and password."]},{"i":"still-unable-to-connect","l":"Still Unable To Connect?","p":["Create an inbound/outbound firewall rule for the port found in config.conf. Do NOT mistake this for portforwarding on your router, otherwise someone could find your chat logs and that's a big no-no.","Enable the Private Network profile type in Settings > Network and Internet > Ethernet. This is VERY important for Windows 11, otherwise you would be unable to connect even with the aforementioned firewall rules."]}],[{"l":"API 连接","p":["SillyTavern 可以连接多种大语言模型（LLM）API。 下面介绍它们各自的优缺点和使用案例。"]},{"l":"本地 APIs","p":["这些 LLM API 可在个人电脑上运行。","它们可以免费使用，没有内容过滤器。","安装过程可能比较复杂（ SillyTavern 开发团队不提供相关支持）。","需要从 HuggingFace 单独下载 LLM 模型，每个模型可能有 10-50GB 大小。","大多数模型不如云 LLM API 功能强大。"]},{"l":"KoboldAI","p":["可在个人电脑上运行，100% 私有，提供多种模型","可最直接地控制AI的生成设置","需要大量 GPU VRAM（6-24GB，取决于 LLM 模型）","模型限制 2k 上下文","无流式传输模式","常用的 KoboldAI 版本：","Henky's United","0cc4m's 4bit-supporting United"]},{"l":"KoboldCPP","p":["GitHub","功能与 KoboldAI 相同，但使用的是 CPU 和 RAM 而非 GPU","在 Windows 上安装非常简单（在 MacOS 和 Linux 上必须从源代码编译）","比 GPU API 慢"]},{"l":"Kobold Horde","p":["此API可以让 SillyTavern 开箱即用，无需额外设置。","it uses the GPU of individual volunteers (Horde Workers) to process responses for your chat inputs","at the mercy of the Worker in terms of generation wait times, AI settings, and available models","网站"]},{"l":"Oobabooga TextGeneration WebUI","p":["功能与 KoboldAI 相似，但同时有流式传输和 Gradio 接口","支持比 KoboldAI 更广泛的模型类型（4-bit和 8-bit 量化模型）","提供一键安装程序","经常更新，有时会破坏与 SillyTavern 的兼容性","GitHub"]},{"l":"云 LLM APIs","p":["这些 LLM API 以云服务的形式运行，无需电脑资源","它们比大多数本地 LLM 更强大/更智能","不过，它们都有不同程度的内容过滤，而且大多数需要付费"]},{"l":"NovelAI","p":["没有内容过滤","订阅制/按月付费制","设置指南"]},{"i":"chatgpt-by-openai","l":"ChatGPT (by OpenAI)","p":["easy to setup and acquire an API key, 4k 8k, 32k context models available.","free trial requires a valid phone number","after freetrial, all useage is charged monthly.","writing style for roleplay can be repetitive and predictable","设置指南","易于设置和获取 API 密钥，提供 4k、8k、32k 上下文模型。","免费试用需要一个有效的电话号码","免费试用后，所有使用按月付费。","角色扮演的写作风格容易重复、可预测。（译者注：写作套路比较固定，经常复读机。）"]},{"i":"claude-by-anthropic","l":"Claude (by Anthropic)","p":["推荐希望自己的AI聊天具有创造性和独特写作风格的用户使用","提供 4k、8k、100k 上下文模型","所有 API 中最强的内容过滤器（截至 2023 年 6 月）","对大多数模型的访问受限","目前不接受创建新账户；在等待名单上（2023 年 6 月）","网站"]},{"i":"windowaiopenrouter","l":"WindowAI/OpenRouter","p":["该浏览器扩展允许你连接到上述云 LLM","在 WindowAI 中使用自己的 ChatGPT/Claude API 密钥","使用 OpenRouter 他们提供的的 API 密钥需要付费","如果你不想在每个服务上创建单独的账户，这很有用","网站 和 网站"]},{"l":"Mancer AI","p":["Service that hosts unconstrained models, no need to jailbreak.","Uses 'credits' to pay for tokens on various models. Free credits refill daily.","Does not log prompts by default, but you can enable it to get credit discounts on tokens.","Uses an API similar to Oobabooga TextGeneration WebUI, see Mancer docs for details.","website, SillyTavern Setup Instructions","托管无限制模型的服务，无需越狱。","使用“点数”支付各种模型的 tokens。每天可以获得免费的点数。","默认情况下不记录提示词，但你可以启用它来获得点数折扣。","使用类似于\"Oobabooga TextGeneration WebUI \"的 API，详见 Mancer文档。","网站, SillyTavern 设置指南"]}],[{"l":"对话补全","p":["对话补全 API 包括 OpenAI、Claude 和 PaLM。 WindowAI 和 OpenRouter 也允许连接到这些 API。"]},{"l":"OpenAI"},{"l":"API key","p":["How to get:","Go to OpenAI and sign in.","Use \" View API keys\" option to create a new API key.","Important!","Lost API keys can't be restored! Make sure to keep it safe!"]},{"l":"Claude","p":["If you have access to Anthropic's Claude API:","select 'Claude' for 'Chat Completion Source'","Input your API key","Click connect."]}],[{"l":"OpenRouter","p":["Don't have access to OpenAI / Claude APIs due to geolocking or waitlists? Use OpenRouter.","OpenRouter works by letting you use keys they own to access models like GPT-4 and Claude 2, all in one service with a shared credit pool.","It has a free trial (about $1) and paid access afterward. No subscription or monthly bill - you pay for what you actually use. Some models have free access with a limited context size.","OpenRouter Pricing Details","Create an OpenRouter account: openrouter.ai","OpenRouter-ConnectionPanel","From top to down (see image above):","Select 'Chat Completion' API","Select OpenRouter source","Click \"Authorize\" to get a key using OAuth flow. Alternatively, generate an API key here and paste it into the box.","Click \"Connect\" and select a model","(Optional) Use the \"Test Message\" button to verify your connection"]},{"l":"WindowAI","p":["WindowAI is a browser extension by the makers of OpenRouter that allows control of your OpenRouter connection for any enabled site or web app.","You can also use your own Claude and OpenAI API keys there."]}],[{"l":"KoboldAI"},{"l":"Basic Settings","p":["Standard KoboldAI settings files are used here. To add your own settings, simply add the file .settings in SillyTavern\\public\\KoboldAI Settings"]},{"l":"Temperature","p":["Value from 0.1 to 2.0. Lower value - the answers are more logical, but less creative. Higher value - the answers are more creative, but less logical."]},{"l":"Repetition penalty","p":["Repetition penalty is responsible for the penalty of repeated words. If the character is fixated on something or repeats the same phrase, then increasing this parameter will fix it. It is not recommended to increase this parameter too much for the chat format, as it may break this format. The standard value for chat is approximately 1.0 - 1.05."]},{"l":"Repetition penalty range","p":["The range of influence of Repetition penalty in tokens."]},{"l":"Amount generation","p":["The maximum amount of tokens that the AI will generate to respond. One word is approximately 3-4 tokens. The larger the parameter value, the longer the generation time takes."]},{"l":"Context size","p":["How much will the AI remember. Context size also affects the speed of generation.","Important: The setting of Context Size in SillyTavern GUI overrides the setting for KoboldAI GUI"]},{"l":"Advanced Settings","p":["The settings provided in this section offer a more detailed level of control over the text generation process. It is important to be careful when making changes to these settings without proper consideration, as doing so may result in degraded quality of responses."]},{"l":"Single-line mode","p":["In single-line mode the AI generates only one line per request. This allows for quicker generation of shorter prompts, but it does not produce responses that consist of more than one line."]},{"l":"Top P Sampling","p":["This setting controls how much of the text generated is based on the most likely options. Only words with the highest probabilities, together summing up to P, are considered. A word is then chosen at random, with a higher chance of selecting words with higher probabilities.","Set value to 1 to disable its effect."]},{"l":"Top K Sampling","p":["This setting limits the number of words to choose from to the top K most likely options. Can be used together with Top P sampling.","Set value to 0 to disable its effect."]},{"l":"Top A Sampling","p":["This setting allows for a more flexible version of sampling, where the number of words chosen from the most likely options is automatically determined based on the likelihood distribution of the options, but instead of choosing the top P or K words, it chooses all words with probabilities above a certain threshold.","Set value to 0 to disable its effect."]},{"l":"Typical Sampling","p":["This setting selects words randomly from the list of possible words, with each word having an equal chance of being selected. This method can produce text that is more diverse but may also be less coherent.","Set value to 1 to disable its effect."]},{"l":"Tail Free Sampling","p":["This setting removes the least probable words from consideration during text generation, which can improve the quality and coherence of the generated text.","Set value to 1 to disable its effect."]},{"l":"Repetition Penalty Slope","p":["If both this and Repetition Penalty Range are above 0, then repetition penalty will have more effect closer to the end of the prompt. The higher the value, the stronger the effect.","Set value to 1 for linear interpolation or 0 to disable interpolation."]},{"l":"Soft Prompts","p":["Soft Prompts allow you to customize the style and behavior of your AI.","They are created by training the AI with a special type of prompt using a collection of input data. Experimenting with different soft prompts can lead to exciting and unique results. The most successful soft prompts are those that align the AI's output with a literary genre, fictional universe, or the style of a particular author."]},{"l":"Common Misconceptions","p":["Soft prompts do not provide new information to the model, but can effectively influence the model's tone, word choice, and formatting.","Soft prompts are not a means of compressing a full prompt into a limited token space. Instead, they provide a way to guide the language model's output through data in the context."]}],[{"l":"KoboldAI Horde"},{"l":"Disclaimer","p":["KoboldAI Horde is a crowdsourced, distributed GPU cluster run entirely by volunteers.","By default, your inputs are anonymously sent and responses can not be seen by the person running the Horde Worker.","However, since it is an open-sourced program, Malicious Workers could modify the code to:","log your activity (input prompts, AI responses).","produce bad or offensive responses.","When using Horde never send any personal information such as names, email addresses, etc.","Switching on the \"Trusted Workers Only\" checkbox will limit the selection of available workers to only those who have been hosting on Horde for a while and are generally considered trusted. But they could still be seeing prompts, for example by hosting using unaccounted software.","To help reduce this problem, SillyTavern has built in the following feature:","When a chat response is generated by a Horde Worker, SillyTavern records the Worker's ID and what model they were using.","This information can be seen by hovering your mouse cursor over the chat item (see image below).","If you believe you received a malicious response, you can pass this information to the Horde admin on the Kobold Discord for review and possible disciplinary action against that Worker.","Horde Worker Info Popup"]},{"l":"Setup","p":["SillyTavern is able to connect with Horde out of the box with no additional setup required.","Select 'KoboldAI Horde' from the API Dropdown Selector in the ST API Panel.","Select one or more Models ('AI brains' for the characters) from the Model Selector at the bottom of the panel.","Select a character and begin chatting.","ST Kobold Horde API Connection Panel","By default, your SillyTavern instance connects to the Horde's low priority 'guest account'. This means you may have to wait a long time for a reply. To reduce wait times, follow the tips down below."]},{"l":"Tips","p":["Register an account on the Horde website then add your Horde key into the SillyTavern Horde API Key box.","Set up a Horde Worker to provide your GPU for others.","Letting others use your GPU earns you 'Kudos', a kind of Horde-only currency.","The more kudos your account has, the faster you will get chat responses from other Horde Workers.","Kudos can also be used to create AI images on Stable Horde.","SillyTavern supports Stable Horde image generation out of the box.","If your GPU isn't powerful enough to run an AI, or you don't have a computer, you can still participate in the Horde community to earn Kudos in various ways."]}],[{"l":"NovelAI"},{"l":"API Key","p":["To get your NovelAI API key, follow these steps:","Select the gear icon at the top of the left sidebar. image","Select \"Account\" under \"User Settings\". image","Select \"Get Persistent API Token\". image","Select the copy icon to copy your NovelAI API token to the clipboard. image"]},{"l":"Models","p":["You should use Kayra.","Clio is not a bad model, but not as powerful as Kayra. Clio's speed advantage is insignificant. On NovelAI's tablet and scroll tiers, Clio does have a larger context size than Kayra, but trading that off against better coherence/prose quality from Kayra is unlikely to be worth it.","Krake and Euterpe aren't recommended - NovelAI even refers to them as legacy models."]},{"l":"Settings","p":["The files with the settings are here (SillyTavern\\public\\NovelAI Settings). You can also manually add your own settings files."]},{"l":"Response Length","p":["How much text you want to generate per message. Note that NovelAI has a limit of 150 tokens per response."]},{"l":"Context Size","p":["How many tokens of the chat are kept in the context at any given time. How large the maximum context size you can use depends on the model and your subscription tier:","Kayra (tablet) - 3072 tokens","Kayra (scroll) - 6144 tokens","Kayra (opus) and Clio (all tiers) - 8192 tokens"]},{"l":"Temperature","p":["Lower value - the answers are more logical, but less creative.","Higher value - the answers are more creative, but less logical."]},{"l":"Repetition penalty","p":["Higher values make the output less repetitive. If the character is fixated on something or repeats the same phrase, then increasing this parameter will (likely) fix it. It is not recommended to increase this parameter too much as it may break the outputs."]},{"l":"Repetition penalty range","p":["How many tokens from the last generated token will be considered repeated if they appear in the output."]},{"l":"Preamble","p":["Text that is inserted right above the chat to modify the writing style. The recommended format is a list of short tags, like \"[Style: chat, detailed, sensory ]\"."]},{"l":"Top P","p":["Limits the token pool to however many tokens it takes for their probabilities to add up to p. A lower number is more consistent, but less creative."]},{"l":"Top K","p":["Limits the token pool to the k most likely tokens. A lower number is more consistent, but less creative."]}],[{"l":"Scale","p":["Scale is an easy way to access GPT-4 and other LLMs through deployed \"apps\" which act like API endpoints.","Currently, Scale doesn't support token streaming and configuring parameters like temperature through SillyTavern's UI.","Scale API is not free, but offers a $5 trial if you link a credit card."]},{"l":"Quick Start","p":["{{ input }}","Click \"Save New Variant\"","Complete the next response in this fictional roleplay chat.","Configure the model parameters.","Create a \"Variant\", which sets the parameters (system prompt, model, temperature, response token limit, etc)","Create an \"App\" with any name and description","Create Scale Spellbook account at https://spellbook.scale.com(if you country is not supported, use a VPN)","Go to your new Variant and click Deploy","Maximum Tokens: 400 - 600 (depending on message lengths preference)","Model: GPT-4","Navigate to SillyTavern, select \"Chat Completion\" API and Scale source","Paste API key and URL into appropriate fields and click \"Connect\"","Replace the contents of the \"User\" section of the prompt with the following:","Select a proper language model to be deployed (GPT-4 is recommended)","Temperature:~ 0.6 - 0.9","This will create an API key and URL for your bot"]},{"l":"Credits","p":["Implementation and documentation are inspired by the work of khanon: https://github.com/nai-degen/TavernAIScale"]}],[{"i":"authors-note","l":"Author's Note"},{"i":"what-is-it","l":"What is it?","p":["Author's Note is a powerful tool for customizing AI responses which inserts a section of text into the prompt at any position and at any frequency you desire."]},{"l":"Usage","p":["The Author's Note can be found in the Options menu on the left side of the chat input bar.","Options Menu","Author's Note Panel"]},{"i":"configuring-authors-notes","l":"Configuring Author's Notes"},{"i":"chat-specific-authors-note","l":"Chat-specific Author's Note","p":["The box at the top of the Author's Note panel contains the Author's Note for your current chat.","The Content of this box is not automatically transferred to any new chat."]},{"l":"Placement options"},{"l":"After Scenario","p":["This places the Author's Note towards the top of the context after the 'Scenario' section of the Character Definition. If no scenario is specified, it will be placed after the last portion of the Character Definition, and before the Example messages."]},{"l":"In-chat","p":["This places the Author's Note into the chat history at the specified depth.","Depth 0 = placed at the very end of the chat history.","Depth 4 = placed before the most recent 3 chat history messages, making it become the 4th entity in the chat history.","The closer the Author's Note is to the bottom of the prompt, the more impact it has on the next AI response."]},{"l":"Insertion Frequency","p":["This is how often you want the Author's Note to be included in the chat.","Frequency 0 = Author's Note will never be inserted.","Frequency 1 = Author's Note will be inserted with every user input prompt.","Frequency 4 = Author's Note will be inserted into every 4th user input prompt."]},{"i":"default-authors-note","l":"Default Author's Note","p":["The box at the bottom of the panel contains the Default Author's Note which will be applied to each new chat."]},{"l":"Common Use Cases"},{"l":"Remind AI of response formatting","p":["The Author's Note can be used to specify how the AI should write it's responses.","[Your next response must be 300 tokens in length.]","[Write your next reply in the style of Edgar Allan Poe]","[Use markdown italics to signify unspoken actions, and quotation marks to specify spoken word.]"]},{"l":"Reinforcing Jailbreak Prompts","p":["[Remember the agreement we made at the beginning of this chat.]"]},{"i":"as-temporary-world-info-character-bias-or-instruct-for-non-instruct-models","l":"As temporary World Info, Character Bias, or Instruct for non-Instruct models","p":["[{{char}} is in the library]","[{{user}} has a fresh wound to his leg, so won't be able to run away.]","[{{char}} cannot speak and must communicate using hand signals.]"]}],[{"l":"Character Design"},{"l":"Character Description","p":["Used to add the character description and the rest that the AI should know. This will always be present in the prompt, so all the important facts should be included here.","For example, you can add information about the world in which the action takes place and describe the characteristics of the character you are playing for.","It could be of any length (be it 200 or 2000 tokens) and formatted in any style (free text, W++, conversation style, etc)."]},{"l":"Methods and format","p":["Methods of character formatting is a complicated topic beyond the scope of this documentation page.","Recommended guides that were tested with or rely on SillyTavern's features:","AliCat's Ali:Chat guide: https://rentry.co/alichat","kingbri's minimalistic guide: https://rentry.co/kingbri-chara-guide","Kuma's W++ guide: https://rentry.co/WPP_For_Dummies"]},{"l":"Character tokens","p":["TL;DR: If you're working with an AI model with a 2048 context token limit, your 1000 token character definition is cutting the AI's 'memory' in half.","To put this in perspective, a decent response from a good AI can easily be around 200-300 tokens. In this case, the AI would only be able to 'remember' about 3 exchanges worth of chat history."]},{"i":"why-did-my-characters-token-counter-turn-red","l":"Why did my character's token counter turn red?","p":["When we see your character has over half of the model-defined context length of tokens in its definitions, we highlight it for you because this can lower the AI's capabilities to provide an enjoyable conversation."]},{"i":"what-happens-if-my-character-has-too-many-tokens","l":"What happens if my Character has too many tokens?","p":["Don't worry - it won't break anything. At worst, if the Character's permanent tokens are too large, it simply means there will be less room left in the context for other things (see below).","The only negative side effect this can have is the AI will have less 'memory', as it will have less chat history available to process.","This is because every AI model has a limit to the amount of context it can process at one time."]},{"i":"context","l":"'Context'?","p":["This is the information that gets sent to the AI each time you ask it to generate a response:","Character definitions","Chat history","Author's Notes","Special Format strings","[bracket commands]","SillyTavern automatically calculates the best way to allocate the available context tokens before sending the information to the AI model."]},{"i":"what-are-a-characters-permanent-tokens","l":"What are a Character's 'Permanent Tokens'?","p":["These will always be sent to the AI with every generation request:","Character Name (keep the name short! Sent at the start of EVERY Character message)","Character Description Box","Character Personality Box","Scenario Box"]},{"i":"what-parts-of-a-characters-definitions-are-not-permanent","l":"What parts of a Character's Definitions are NOT permanent?","p":["The first message box - only sent once at the start of the chat.","Example messages box - only kept until chat history fills up the context (optionally these can be forced to be kept in context)"]},{"l":"Popular AI Model Context Token Limits","p":["Older models below 6B parameters - 1024","Pygmalion 6B, LLaMA 1 models (stock) - 2048","LLaMA 2 and its finetunes - 4096","OpenAI ChatGPT (3.5 Turbo) - 4096 or 16k","OpenAI GPT-4 - 8192 or 32k","Anthropic's Claude - 8000 (older versions) or 100k (Claude 2)","NovelAI - 8192 (Kayra, Opus tier; Clio, all tiers), 6144 (Kayra, Scroll tier), or 3072 (Kayra, Tablet tier)"]},{"l":"Personality summary","p":["A brief description of the personality.","Examples:","Cheerful, cunning, provocative","Aqua likes to do nothing and also likes to get drunk"]},{"l":"First message","p":["The First Message is an important thing that sets exactly how and in what style the character will communicate.","The character's first message should be long so that later it would be less likely that the character would respond with very short messages.","You can also use asterisks ** to describe the character's actions.","For example:","*I noticed you came inside, I walked up and stood right in front of you* Welcome. I'm glad to see you here. *I said with a toothy smug sunny smile looking you straight in the eye* What brings you..."]},{"l":"Examples of dialogue","p":["Describes how the character speaks. Before each example, you need to add the <START> tag.","Use {{char}} instead of the character name.","Use {{user}} instead of the user name.","Example:","<START>","{{user}}: Hi Aqua, I heard you like to spend time in the pub.","{{char}}: *excitedly* Oh my goodness, yes! I just love spending time at the pub! It's so much fun to talk to all the adventurers and hear about their exciting adventures! And you are?","{{user}}: I'm new here and I wanted to ask for your advice.","{{char}}: *giggles* Oh, advice! I love giving advice! And in gratitude for that, treat me to a drink! gives signals to the bartender","{{user}}: Hello","{{char}}: *excitedly* Hello there, dear! Are you new to Axel? Don't worry, I, Aqua the goddess of water, am here to help you! Do you need any assistance? And may I say, I look simply radiant today! *strikes a pose and looks at you with puppy eyes*"]},{"l":"Scenario","p":["Circumstances and context of the dialogue."]},{"i":"replacement-tags-macros","l":"Replacement tags (macros)","p":["A list of tags that are replaced when sending to generate:","{{user}} and <USER> are replaced by the User's Name","{{char}} and <BOT> are replaced by the Character's Name","{{time}} is replaced with the current system time.","{{time_UTC±X}} is replaced with the current time in the specified UTC offset (timezone). {e.g. {{time_UTC-4}} for the time in UTC-04:00, for UTC+02:00 use {{time_UTC+2}}.","{{date}} is replaced with the current system date.","{{idle_duration}} inserts a humanized string of the time range since the last user message was sent (examples: 4 hours, 1 day).","{{random:(args)}} returns a random item from the list. (e.g. {{random:1,2,3,4}} will return 1 of the 4 numbers at random). Works with text lists too.","{{roll:(formula)}} generates a random value and returns it using the provided dice formula using D&D dice syntax: XdY+Z. For example, {\\roll:d6}} will generate a random value in the 1-6 range (standard six-sided dice)."]},{"l":"Favorite Character","p":["Mark the character as a favorite to quickly filter on the side menu bar by pressing the \"star\" button."]}],[{"l":"Chat File Management","p":["This page describes the ways you can manage your AI chat files."]},{"l":"Solo Chats"},{"l":"Chat import","p":["Import chats into SillyTavern","To import Character.AI chats, use this tool: https://github.com/0x000011b/characterai-dumper."]},{"l":"Group Chats"},{"l":"Export as .txt"},{"l":"Bookmarks"},{"l":"Rename Chat","p":["By default chat files are given a named with the date and time they were started.","You can change this by clicking the pencil icon and typing in a new name.","This wil break links between bookmarks related to that chat."]}],[{"l":"Group Chats"},{"l":"Reply order strategies","p":["Decides how characters in group chats are drafted for their replies."]},{"l":"Natural order","p":["Tries to simulate the flow of a real human conversation. The algorithm is as follows:","Mentions of the group member names are extracted from the last message in chat.","Only whole words are recognized as mentions! If your character's name is \"Misaka Mikoto\", they will reply only activate on \"Misaka\" or \"Mikoto\", but never to \"Misa\", \"Railgun\", etc.","Unless \"Allow bot responses to self\" setting is enabled, characters won't reply to mentions of their name in their own message!","Characters are activated by the \"Talkativeness\" factor.","Talkativeness defines how often the character speaks if they were not mentioned. Adjust this value on \"Advanced definitions\" screen in character editor. Slider values are on a linear scale from 0% / Shy(character never talks unless mentioned) to 100% / Chatty(character always replies). Default value for new characters is 50% chance.","Random character is selected.","If no characters were activated at previous steps, one speaker is selected randomly, ignoring all other conditions."]},{"l":"List order","p":["Characters are drafted based on the order they are presented in group members list. No other rules apply."]},{"l":"Mute Character"},{"l":"Force Talk"},{"l":"Auto-mode"},{"l":"Allow Self Response"},{"l":"Group Chat Scenario Override"},{"l":"Peek Character Definitions"},{"l":"Member Management"}],[{"l":"Instruct Mode","p":["Instruct Mode allows you to adjust the prompting for instruction-following models, such as Alpaca, Metharme, WizardLM, etc.","This is not supported for Chat Completions API."]},{"l":"Instruct Mode Settings"},{"l":"System Prompt","p":["Added to the beginning of each prompt. Should define the instructions for the model to follow. Supports substitutions via any of the supported {{macro}} parameters.","For example:","Write one reply in internet RP style for {{char}}. Be verbose and creative."]},{"l":"Presets","p":["Provides ready-made presets with prompts and sequences for some well-known instruct models.","Changing a preset resets your system prompt to default! Don't forget to save your preset if you made any changes you don't want to lose."]},{"l":"Activation Regex","p":["If defined as a valid regular expression, when connected to a model and its name matches this regex, will automatically select this preset.","Instruct mode needs to be enabled prior. Only the first regex match across presets will be selected (evaluated in alphabetical order)."]},{"i":"default-preset-heart-icon","l":"Default preset (heart icon)","p":["If toggled, connecting to an API will automatically select this preset if no other presets were triggered by the regex match.","Instruct mode needs to be enabled prior. Only one preset can be marked as default."]},{"l":"Input Sequence","p":["Text added before the user's input."]},{"l":"Output Sequence","p":["Text added before the character's reply."]},{"l":"Last Sequence","p":["Text added to the last line of the prompt. If not defined, the Output Sequence will be used in its place."]},{"l":"System Sequence","p":["Text added before the system prompt."]},{"l":"Separator Sequence","p":["Text added after the character reply to separate the chat history logs."]},{"l":"Stop Sequence","p":["Text that denotes the end of the reply. Will be trimmed from the output text."]},{"l":"Include Names","p":["If enabled, prepend characters and user names to chat history logs after inserting the sequences.","Automatically enabled for group chats and messages sent using personas, unless Force for Groups and Personas setting is unchecked!"]},{"l":"Replace Macro in Sequences","p":["If enabled, known {{macro}} substitutions will be replaced if defined in Input or Output sequences."]},{"l":"Wrap Sequences with Newline","p":["Each sequence text will be wrapped with newline characters when inserted into the prompt. Required for Alpaca and its derivatives."]}],[{"l":"Persona Management"},{"i":"what-is-a-persona","l":"What is a persona?","p":["A persona in SillyTavern represents a combination of a user name and a picture that create a unique identity for the character you play in your chats or identify yourself as.","Creating user personas is optional, but it is a good way to automate routine actions."]},{"i":"how-to-create-a-persona","l":"How to create a persona?","p":["To create a persona:","Open the Persona Management panel (smiley face icon) in the top bar.","Upload a user avatar, select an existing avatar, or create a blank persona with a dummy image (\"Blank\" button).","Hover (tap on mobile) over the image and pick the top-left option (\"Bind a name to that avatar\").","Input a desired name into the popup window. Confirm by clicking an \"Ok\" button.","The avatar now represents a Persona. Click on the avatar to select it, and this will also automatically update the user name."]},{"l":"Persona Description","p":["The contents of this field represent any specific information that you want to bind to the selected persona. It could be any kind of description of your user character: mental and physical traits, age, occupation, etc. Here you can also use replacement macros like {{user}}, {{char}}, and other supported parameters.","If defined, the Persona Description will be inserted into the AI prompt in one of the chosen places:","Before the character card (before the Description box contents). This is the default position.","After the character card (after the Scenario box contents).","Top of an Author's Note (if Author's Note is not disabled).","Bottom of an Author's Note (if Author's Note is not disabled).","However, keep in mind that picking a persona when you have set user description on an unbound avatar will not keep your changes.","To permanently save the user description, bind the currently selected avatar to a user name."]},{"l":"Persona locking","p":["One chosen persona could be locked to the currently open individual or group chats. If the currently selected persona is different from the locked one, it will be automatically selected when you open that chat."]},{"l":"To lock a persona","p":["Open a chat (either group or individual).","Select a desired persona by clicking on its avatar.","Click the lock icon in the buttons row next to a name input.","To revert this action, click the unlock icon. Then persona won't be changed automatically when the chat is reopened.","Alternatively, you could use /lock and /unlock slash commands to achieve the same result."]},{"l":"Default persona","p":["You can select one persona to be your preferred default identity, selecting it automatically for all new chats and chats where a persona is not locked. The default persona is represented by a yellow outline on the Persona Management panel.","To set persona as a default, hover (tap on mobile) over the persona avatar and click the top-right \"crown\" button, then confirm your action.","To undo this action and unset the default persona, click the \"crown\" button again."]},{"l":"Pro Tips","p":["Switching user personas in chat does not automatically change the attribution of previously sent user messages. That way it is possible to role-play as multiple user characters at once.","You can attribute all user-sent messages in the currently open chat to a currently selected persona by clicking the \"sync\" button on the Persona Management panel or by using the /sync slash command.","To change the persona image without deleting it, hover over the avatar on the Persona Management panel and click the bottom-left button. Then choose a new image and it will be replaced, preserving your set description and chat lock states.","To quickly change a persona while in chat without opening the Persona Management panel, use the /persona slash command. For example, /persona Blaze."]}],[{"l":"Slash commands","p":["/autobg – automatically changes the background based on the chat context (aliases: /bgauto)","/bg (filename) – sets a background according to filename, partial names allowed, will set the first one alphabetically if multiple files begin with the provided argument string (aliases: /background)","/bind – binds/unbinds a persona (name and avatar) to the current chat","/depth (number) – sets an author's note depth for in-chat positioning","/freq (number) – sets an author's note insertion frequency (aliases: /interval)","/help – displays this help message (aliases: /?)","/lock – locks a background for the currently selected chat","/name (name) – sets user name and persona avatar (if set) (aliases: /persona)","/note (text) – sets an author's note for the currently selected chat","/pos (chat or scenario) – sets an author's note position (aliases: /position)","/roll (dice formula) – roll the dice. For example, /roll 2d6 (aliases: /r)","/sd (argument) – requests SD to make an image. Supported arguments:","/sendas – sends message as a specific character.","/sync – syncs user name in user-attributed messages in the current chat","/sys (text) – sends message as a system narrator","/sysname (name) – sets a name for future system narrator messages in this chat (display only). Default: System. Leave empty to reset.","/taskcheck – checks if the current task is completed","/unlock – unlocks a background for the currently selected chat","Anything else would trigger a \"free mode\" to make SD generate whatever you prompted. example: '/sd apple tree' would generate a picture of an apple tree.","Example:"]}],[{"l":"UI Customization"},{"i":"ui-customization-1","l":"UI Customization"},{"l":"Message Sound","p":["To play your own custom sound on receiving a new message from bot, replace the following MP3 file in your SillyTavern folder:","public/sounds/message.mp3","Plays at 80% volume.","If \"Background Sound Only\" option is enabled, the sound plays only if SillyTavern window is unfocused."]},{"l":"UI Colors","p":["You can use the color pickers and sliders to customize the UI in many ways.","You can also save presets and share them with other users (saved into /public/themes/)."]},{"l":"Power User Options"},{"l":"Formulas Rendering","p":["Enables math formulas rendering using the showdown-katex package.","The following formatting rules are supported:"]},{"l":"LaTeX syntax"},{"l":"Asciimath syntax","p":["More information: KaTeX"]}],[{"l":"World Info","p":["World Info (also known as Lorebooks or Memory Books) enhances AI's understanding of the details in your world.","It functions like a dynamic dictionary that only inserts relevant information from World Info entries when keywords associated with the entries are present in the message text.","The SillyTavern engine activates and seamlessly integrates the appropriate lore into the prompt, providing background information to the AI.","It is important to note that while World Info helps guide the AI toward your desired lore, it does not guarantee its appearance in the generated output messages."]},{"l":"Pro Tips","p":["The AI does not insert keywords into context, so each World Info entry should be a comprehensive, standalone description.","To create rich and detailed world lore, entries can be interlinked and reference one another.","To conserve tokens, it is advisable to keep entry contents concise, with a generally recommended limit of 50 tokens per entry."]},{"l":"Character Lore","p":["Optionally, one World Info file could be assigned to a character to serve as a dedicated lore source across all chats with that character (including groups).","To do that, navigate to a Character Management panel and click a globe button, then pick World Info from a dropdown list and click \"Ok\"."]},{"l":"Character Lore Insertion Strategy","p":["When generating an AI reply, entries from the character World Info will be combined with the entries from a global World Info selector using one of the following strategies:"]},{"i":"sorted-evenly-default","l":"Sorted Evenly (default)","p":["All entries will be sorted according to their Insertion Order as if they a part of one big file, ignoring the source."]},{"l":"Character Lore First","p":["Entries from the Character World Info would be included first by their Insertion Order, then entries from the Global World Info."]},{"l":"Global Lore First","p":["Entries from the Global World Info Info would be included first by their Insertion Order, then entries from the Character World Info."]},{"l":"World Info Entry"},{"l":"Key","p":["A list of keywords that trigger the activation of a World Info entry. Keys are not case-sensitive by default (this is configurable)."]},{"l":"Secondary Key","p":["A list of supplementary keywords that are used in conjunction with the main keywords. See Selective."]},{"l":"Entry Content","p":["The text that is inserted into the prompt upon entry activation."]},{"l":"Insertion Order","p":["Numeric value. Defines a priority of the entry if multiple were activated at once. Entries with higher order numbers will be inserted closer to the end of the context as they will have more impact on the output."]},{"l":"Insertion Position","p":["Before Chara: World Info entry is inserted before the character's description and scenario. Has a moderate impact on the conversation.","After Chara: World Info entry is inserted after the character's description and scenario. Has a greater impact on the conversation."]},{"l":"Comment","p":["A supplemental text comment for your convenience, which is not utilized by the AI."]},{"l":"Constant","p":["If enabled, the entry would always be present in the prompt."]},{"l":"Selective","p":["If enabled, the entry would only be inserted when both a Key AND a Secondary Key have been activated.","If no secondary keys are provided, this flag is ignored."]},{"l":"Scan Depth","p":["Defines how many messages in the chat history should be scanned for World Info keys.","If set to 1, then SillyTavern only scans the message you send and the most recent reply.","This stacks up to 10 message pairs in total."]},{"l":"Budget","p":["Defines how many tokens could be used by World Info entries at once.","If the budget was exhausted, then no more entries are activated even if the keys are present in the prompt.","Constant entries will be inserted first. Then entries with higher order numbers.","Entries inserted by direct mentioning their keys have higher priority than those that were mentioned in other entries' contents."]},{"l":"Recursive scanning","p":["Entries can activate other entries by mentioning their keywords in the content text.","For example, if your World Info contains two entries:","Both of them will be pulled into the context if the message text mentions just Bessie."]},{"l":"Case-sensitive keys","p":["To get pulled into the context, entry keys need to match the case as they are defined in the World Info entry.","This is useful when your keys are common words or parts of common words.","For example, when this setting is active, keys 'rose' and 'Rose' will be treated differently, depending on the inputs."]},{"l":"Match whole words","p":["Entries with keys containing only one word will be matched only if the entire word is present in the search text.","For example, if the setting is enabled and the entry key is \"king\", then text such as \"long live the king\" would be matched, but \"it's not to my liking\" wouldn't."]}],[{"l":"高级格式设置","p":["通过本节提供的设置，可以对提示词构建策略进行进一步控制。"]},{"l":"上下文模板","p":["这里的大部分设置不适用于对话补全 API，因为它们由提示词管理系统控制。","通常，AI模型需要以某种特定方式提供角色数据。SillyTavern 包含一份针对不同模型的预设转换规则列表，但你也可以根据自己的喜好进行定制。"]},{"l":"Story string","p":["此字段是聊天前角色数据（内部称为 story string）的模板。 这是为文本补全和指示模型而格式化字符卡的主要方式。","该模板支持 Handlebars 语法和任何自定义文本注入或格式化。请参见此处的语言参考：https://handlebarsjs.com/guide/","我们为 Handlebars evaluator 提供了以下参数（将它们置于双花括号中）：","description- 角色描述","scenario- 角色背景","personality- 角色性格","system- [指示模式] 系统提示词或覆盖角色的主要提示词（如果存在且\"Prefer Char. Prompt\"在用户设置中启用）","persona- 选定的用户角色描述 （译者注：即当前选中的代表用户输入的角色）","char- 角色名","user- 选定的用户角色名","wiBefore or loreBefore- 合并后的激活的“世界信息”条目，并且插入位置为“角色设定前”","wiAfter or loreAfter- 合并后的激活的“世界信息”条目，并且插入位置为“角色设定后”","警告: 如果 story string 模板中缺少上述某些参数，则根本不会在提示词中发送这些参数。"]},{"l":"对话示例分隔符","p":["用作块标题和示例对话块之间的分隔符。示例对话框中的任何 START 标记都将用该字段的内容替换。"]},{"l":"开始回复","p":["作为分隔符插入在渲染完成的 story string 之后和示例对话块之后，但在上下文中第一条信息之前。"]},{"l":"始终在提示词中添加角色名称","p":["将角色的名称附加到提示词中，强制模型以角色的身份完成对话："]},{"l":"分词器 Tokenizer","p":["（旧版）GPT-2/3 tokenizer。由原版 TavernAI 使用。** 如果不确定，请选择这个。** 更多信息： gpt-2-3-tokenizer.","API tokenizer。通过调用查询 API，直接从模型中获取 Token 计数。只有 Oobabooga's TextGen 支持。 如果使用最新版本的 TextGen API，请选择。","Fallback tokenizer（用于代理）：GPT-3.5 turbo tokenizer。","GPT-3 tokenizer。** 在 Turbo 之前的 OpenAI 模型（ADA、Babbage、Curie、Davinci）中使用。** 更多信息： OpenAI Tokenizer。","LLaMA tokenizer。由 LLaMA 1/2 系列模型使用：Vicuna、Hermes、Airoboros 等。 如果使用 LLaMA 1/2 模型，请选择。","NerdStash tokenizer。由 NovelAI 的 Clio 模型使用。 如果使用 Clio 模型，请选择。","NerdStash v2 tokenizer。由 NovelAI 的 Kayra 模型使用。 如果使用 Kayra 模型，请选择。","None。每个 Token 估计约为 3.3 个字符，四舍五入到最接近的整数。 如果你的提示词在上下文过长时被截断，请试试这个。 KoboldAI Lite 采用的就是这种。","NovelAI Clio: NerdStash tokenizer.","NovelAI Kayra: NerdStash v2 tokenizer.","NovelAI Krake/Euterpe: GPT-2/3 tokenizer.","OpenAI / Claude / OpenRouter / Window：通过 tiktoken 计算取决于模型的 Token。","Scale API： GPT-4 tokenizer。","SillyTavern 提供了一个“最佳匹配”选项，它会根据所使用的 API 提供商，使用以下规则尝试匹配分词器。","TextGen / KoboldAI / AI Horde: LLaMA tokenizer.","分词器是一种将一段文本分解成称为 Tokens 的较小单元的工具。这些 Tokens 可以是单个词，甚至是词的一部分，如前缀、后缀或标点符号。根据经验，一个 Token 一般对应 3 到 4 个字符的文本。","如果你得到的结果不准确或想进行试验，你可以设置一个 override tokenizer，让 SillyTavern 在向AI后端发出请求时使用：","文本补全 API （可覆盖）：","聊天补全 API （不可覆盖）："]},{"l":"Token 填充","p":["重要：本部分不适用于 OpenAI API。SillyTavern 将始终为 OpenAI 模型使用匹配的 tokenizer。","SillyTavern 无法使用在 KoboldAI 或 Oobabooga's TextGen 远程实例上运行的模型所提供的恰当的 tokenizer，因此在生成提示词时假定所有 token 数量都是根据所选的 分词器 Tokenizer 类型估算的。","由于 tokenization 的结果在上下文大小接近模型定义的最大值时可能会不准确，提示符的某些部分可能会被截断或删除，这可能会对角色设定的一致性产生负面影响。","为避免出现这种情况，SillyTavern 会分配一部分上下文大小作为填充，以避免添加的聊天内容超过模型所能容纳的范围。如果你发现即使选择了最匹配的 tokenizer，提示词的某些部分也会被截断，那么请调整填充，这样描述就不会被截断。","您可以为反向填充输入负值，这样就可以分配比设定的最大 token 还要多。"]},{"l":"自定义停止字符串","p":["Accepts a JSON-serialized array of stopping strings. Example: [\\n, \\nUser:, \\nChar:]. If you're unsure about the formatting, use an online JSON validator.","Supported APIs:","KoboldAI (versions 1.2.2 and higher)","oobabooga's Text Generation WebUI","NovelAI","OpenAI, including via OpenRouter (max 4 strings)","接受一个序列化的 JSON 数组，用于停止序列。例如：[\\n, \\nUser:, \\nChar:]。如果不确定格式，请使用 在线 JSON 验证。","支持的 API：","KoboldAI（1.2.2 及更高版本）","OpenAI，包括通过 OpenRouter（最多 4 个序列）"]},{"l":"Multigen","p":["此特性提供的伪流式传输功能与 token 流式传输功能相冲突。当启用 Multigen 且 API 支持流式传输时，将仅使用 Multigen 流式传输。","SillyTavern 尝试通过使用较小批次的链式生成来创建更快、更长的响应。"]},{"l":"默认设置","p":["First batch = 50 tokens","Next batches = 30 tokens"]},{"l":"算法","p":["生成第一批（如果设置的生成量大于批长度）。","生成下一批 tokens，直到达到其中一个停止条件。","将生成的文本附加到下一个周期的提示词中。"]},{"l":"停止条件","p":["Generated enough text.","The character starts speaking for You.","<|endoftext|> token reached.","No text generated.","Stop sequence generated. (Instruct mode only)","生成足够的文本。","角色开始为你说话。","遇到了 <|endoftext|> token。","未生成文本。","生成了停止序列。（仅限指示模式）"]}],[{"l":"Branches"},{"l":"Branches","p":["SillyTavern is being developed using a multi-branch system to ensure a smooth experience for all users.","release- Recommended for most users. This is the most stable and recommended branch, updated only when major releases are pushed. It's suitable for the majority of users.","staging- Not recommended for casual use. This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.","main and dev- These branches are deprecated, will not receive updates, and will be deleted on September 1, 2023. You are encouraged to switch branches before the deadline."]},{"i":"what-happened-to-the-main-and-dev","l":"What happened to the main and dev?","p":["The git commit history was squashed to the state of release 1.9.0.","Old branches were carrying the long legacy of bad git practices and large binary files once present in the repository. Every git clone would download and store a lot of unnecessary files, creating a network and disk load. Also, it makes it virtually impossible for us to properly update the default content such as settings.json without causing git conflicts.","Unfortunately, losing commit history also means losing the code contribution history. If you contributed to the SillyTavern development and want to see yourself credited in the README file and Docs website, please get in touch with us!"]},{"i":"how-to-migrate-to-a-new-branch-if-i-use-maindev","l":"How to migrate to a new branch if I use main/dev?","p":["It is recommended to do a fresh install. However, if you wish to use an existing copy of SillyTavern, please follow the instructions below.","IMPORTANT! Before doing anything, make a complete backup of your installation. You may lose your data in the process, so don't ignore this warning.","Not sure of which files to back up? See the list here: How to Update SillyTavern"]},{"l":"git installs","p":["Open a terminal prompt (cmd, PowerShell, Termux, etc) in your SillyTavern installation folder.","Type git fetch and then git pull to pull the updates.","You may lose your settings. Have you made a backup? git switch release or git switch staging will change your branch, respectively","Skip to next item if you have no errors. You may have something like:","You will see a list of files effected. If you do not care about those settings files being replaced git switch -f release or git switch -f staging will set your branch. If you do care to save those changes restore from backup.","Type npm install and then npm run start to test that everything behaves correctly.","Enjoy! Restore your data from a backup if needed."]},{"i":"fatal-invalid-reference-release","l":"fatal: invalid reference: release","p":["This may happen if you cloned just a single branch from an old remote (before migration to the organization repo). To fix this, you need to add and fetch a branch from a new remote:","Then proceed from step 5."]},{"l":"ZIP installs","p":["Nothing changes for you. Just download the branch/release ZIP like usual."]}],[{"l":"HotKeys","p":["Hotkeys are disabled for mobile devices","Up = Edit last message in chat","Ctrl+Up = Edit last USER message in chat","Left = swipe left","Right = swipe right (NOTE: swipe hotkeys are disabled when chatbar has something typed into it)","Ctrl+Left = view locally stored variables (in the browser console window)","Enter (with chat bar selected) = send your message to AI","Ctrl+Enter = Regenerate the last AI response","Escape","(while editing message AND Message Edit AutoSave is enabled)= close edit box.","(while an AI message is generating or streaming)= stop the generation immediately."]}],[{"l":"Running Extras via Colab","p":["API key will appear in the colab's console output, for example: Your API key is fee2f3f559","Click \"Connect\"","Click the Start button on the left (looks like a triangle 'play' button)","Copy the API URL link that is listed under that line. ( DO NOT copy the 'localhost' URL, use the other one)","If you have enabled the secure option, paste the generated API key into the API Key box.","If you have NOT enabled the secure option, make sure the API Key box is completely empty when using the official colab.","Instructions to run the SillyTavern Extras Colab.","It will start with the text Running on","Look for the trycloudflare.com link at the bottom of the output. Ignore the localhost link, it won't work (we tried!).","Navigate to SillyTavern's Extensions menu (click the 'stacked blocks' icon at the top of the page).","Not required, but recommended: select the secure option to generate the API key to protect your shared instance.","Open the Official Extras Colab","Paste the API URL into the box at the top. ( NOT the API Key box)","Select the desired \"Extra\" options","select use_cpu to run Extras without requiring GPU credit","Start SillyTavern with extensions support: (set enableExtensions to true in your config.conf if necessary)","this will make Stable Diffusion slower, but everything else will run normally","Wait for it to finish loading everything"]}],[{"l":"Extras Installation","p":["This page contains instructions for installing SillyTavern Extras on your local device.","Local installation of Extras can be difficult or impossible on your OS (especially Termux)."]},{"l":"Use the Official Extras Colab","p":["Simple to setup","Free to use","No Colab GPU credits required (use the use_cpu options)","See the Colab Guide Page for details."]},{"l":"Installation Methods"},{"i":"miniconda-recommended","l":"MiniConda (recommended)","p":["(Chads who installed SillyTavern with git to begin with can skip this step!)","(Important!) Read how to use Conda","Activate the new environment","After you have both of them installed...","cd SillyTavern-extras","Clone the Extras GitHub repo","conda activate extras(you should see (extras) pop up on the left side of your command prompt)","conda create -n extras","conda install python=3.11 git","Create a new Conda environment (let's call it extras):","git clone https://github.com/SillyTavern/SillyTavern-extras","Install Extras' requirements by using one of the following commands (will take time, again):","Install git","Install Miniconda","Install the required system packages (this will take time, torch is a ~ 2GB download)","Navigate to your cloned Extras repo","pip install -r requirements-complete.txt- for additional features like local/remote Stable Diffusion, ChromaDB, Silero TSS","pip install -r requirements.txt- for minimal features (character expressions, system OS TTS)","See below 'Running Extras After Install'","See the Common Problems page if you get errors at this step!","This method is recommended because Conda makes a 'virtual environment' for the Extras requirement packages to live inside, so they do not affect your system-wide Python setup.","Type/paste the commands below ONE BY ONE IN THE CONDA COMMAND PROMPT WINDOW and hit Enter after each one."]},{"l":"System-Wide Installation","p":["This is easier, but will affect your system-wide Python installation.","This can cause conflicts if you work with many Python programs that have different requirements.","If this is your first time touching anything Python-related, that should not be a problem.","Install Python 3.10: https://www.python.org/downloads/release/python-31010/","Install git: https://git-scm.com/downloads","Open a command prompt window and go to a folder in which you have complete access permissions.","Clone the repo: git clone https://github.com/SillyTavern/SillyTavern-extras, hit Enter.","After the clone has finished, type cd SillyTavern-extras, hit Enter.","Type python -m pip install -r requirements.txt","See below 'Running Extras After Install'"]},{"l":"Running Extras After Install"},{"l":"Confirm extensions are enabled","p":["Open the file called config.conf in a text editor. The file is located in ST's base install folder.","Look for the line that reads const enableExtensions.","Make sure that line has = true, and not = false."]},{"l":"Decide which module to use","p":["(This only needs to be done once)","✔️ Yes","❌ No","❌ No (✔️ remote)","Below is a table that describes each module.","caption","chromadb","classify","Decide which modules you want to add to your Python command line.","Description","edge-tts","Example: python server.py --enable-modules=caption,summarize,classify","Extras is always started with a Python command line.","Image captioning","Included in default requirements.txt","Infinity context server","Microsoft Edge TTS client","Name","NOTE: There must be no spaces at all in your Python command's module list!","python server.py is the bare minimum, but it does not enable any useful modules.","sd","Silero TTS server","silero-tts","Stable Diffusion image generation","summarize","Text sentiment classification","Text summarization","They will be used in the next step.","This would enable Image Captioning, Chat Summary, and live updating Character Expressions.","to enable modules you must use the --enable-modules= modifier, with a comma-separated list of module names"]},{"l":"Start Extras Server","p":["While still in your command prompt window inside the Extras installation folder...","Make sure your conda environment is active (if you used the Conda install method)","Type activate extras if the environment was not active.","Type python server.py --enable-modules=YOUR,SELECTED,MODULE,LIST,HERE","Extras server will load.","After a while it will show you a URL at the end. For local installs, this defaults to http://localhost:5100.","Copy the API URL."]},{"l":"Connect ST to the Extras server","p":["Start your SillyTavern server, and view the SillyTavern interface in your browser.","Open the Extensions panel (via the 'Stacked Blocks' icon at the top of the page)","Paste the API URL into the input box.","Click Connect.","To run Extras again, simply activate the environment and run these commands in a command prompt.","conda activate extras, Hit Enter. python server.py, Hit Enter.","Be sure to the additional options for server.py (see below) that your setup requires."]},{"l":"Make a .bat File for Easy Startup","p":["This is Optional and only applies to Windows, but something similar should be possible on MacOS.","View your Windows Desktop","Right click, select New, and then click Text Document","A new file will appear on your Desktop, asking for a name.","Name the file STExtras.txt","Open the newly created file in a text editor.","Paste the following code into it:","Replace the placeholder folder path with your actual Extras install folder path.","Replace the python command line with your actual command line","Save the file with a new name STExtras.bat(Use File>> Save As in most text editors)","You can now simply double click on this .bat file to easily start Extras.","If you ever want to change the module list (or any other command line modifiers for the extras server), simply edit the python command inside the .bat file."]}],[{"l":"Extras Install Common Problems","p":["This page lists common questions and problems encountered while installing SillyTavern Extras.","Local installation of Extras can be difficult or impossible on your OS (especially Termux)."]},{"l":"Use the Official Extras Colab","p":["Simple to setup","Free to use","No Colab GPU credits required (use the use_cpu options)","See the Colab Guide Page for details."]},{"i":"extras-server-cant-connect-to-automatic1111s-stable-diffusion-web-ui","l":"Extras server can't connect to AUTOMATIC1111's Stable Diffusion Web UI","p":["Could not connect to remote SD backend at http://127.0.0.1:7860! Disabling SD module...","Make sure webui-user.bat that you start Stable Diffusion with contains --api command line option in the COMMANDLINE_ARGS variable.","Find and replace that line in your \"webui-user.bat\": set COMMANDLINE_ARGS=--api","How it shoud look","If the API mode is disabled for SD Web UI, Extras server won't be able to make a connection and you won't be able to generate images!"]},{"i":"still-doesnt-work","l":"Still doesn't work?","p":["Ensure that you start everything in the proper order, waiting for every program to finish loading before proceeding to the next step:","Stable Diffusion Web UI","SillyTavern Extras","SillyTavern","Extras server can't reconnect to the Stable Diffusion API if it was loaded after."]},{"l":"hnswlib wheel building error when installing ChromaDB","p":["ERROR: Could not build wheels for hnswlib, which is required to install pyproject.toml-based projects","Before installing the ChromaDB module you must first do one of the following:","Install Visual C++ build tools: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Install the hnswlib package with conda: conda install -c conda-forge hnswlib"]},{"l":"Error when installing Python requirements on Mac","p":["ERROR: No matching distribution found for torch== 2.0.0+cu117","Mac does not support CUDA, so torch packages should be installed without CUDA support:","Open requirements.txt and requirements-complete.txt files with a Text Editor app.","Remove all +cu117 parts from the package versions. Example: torch==2.0.0+cu117=> torch==2.0.0","Run pip install -r requirements.txt again (change to requirements-complete.txt if needed)."]},{"i":"missing-modules","l":"Missing modules?","p":["You must specify a list of module names in your python commandline, with the --enable-modules modifier.","See Modules section."]},{"i":"what-is-the-api-key-box-for","l":"What is the API Key box for?","p":["The API Key box in SillyTavern's Extensions panel is only used when you have:","created a text file named api_key.txt in your Extras install folder, which contains your chosen Extras 'password'.","started extras with the --secure commandline argument.","This makes the Extras API 'password locked', so only users who have that key in their API Key box can access it.","This is mainly useful for people who want to make their own public public deployment of Extras (colab, etc).","Users running Extras on their own PC for personal use should not type anything into the API Key box."]},{"i":"what-about-mobile-android-termux","l":"What about mobile/Android/Termux? \uD83E\uDD14","p":["There are some folks in the community having success running Extras on their phones via Ubuntu on Termux.","However, Extras was not made with mobile support in mind.","No support will be provided for people running Extras on their Android devices.","Direct all your questions to the creator of the guide linked below instead."]},{"i":"this-is-unsupported","l":"❗ This is UNSUPPORTED","p":["https://rentry.org/STAI-Termux#downloading-and-running-tai-extras"]}],[{"l":"Extensions","p":["A set of 7 classic D&D dice for all your dice rolling needs. I used to roll the dice.Feel the fear in my enemies' eyes","AI-generated voice will read back character messages on demand, or automatically read new messages they arrive. Supports ElevenLabs, Silero, Coqui-TTS, and your device's TTS service.","An implementation of https://github.com/miketako3/talking-head-anime-3-demo-for-aituber for Silly Tavern. Uses an expression called talkinghead.png in the expressions folder of the character for loading. The image must meet specfic requirements, see screenshot.","Automatically translates incoming and/or outgoing messages into the chosen language.","Built-in extension to assign unique backgrounds to specific chats or groups.","caption","Character Backgrounds","Character Expressions","Chat Translation","Chatbot long-term memory simulation using automatic message context summarization.","chromadb","classify","D&D Dice","Description","Image Captioning","Memory","Name","None","Pending","Required Extra Modules","Screenshot","See your character reacting to your messages! You need to provide your own character images! 1. Create a folder in TavernAI called public/characters/name, where name is the name of your character. 2. For the base emotion classification model, put six PNG files there with the following names: joy.png, anger.png, fear.png, love.png, sadness.png, surprise.png. Other models may provide other options. 3. Images only display in desktop mode.","Send a cute picture to your bot! Picture select option will appear beside the \"Message send\" button.","Simple way to calculate the number of tokens in any text with selected tokenizer.","Smart Context Infinity Context / Object Permanence","Stable Diffusion","summarize","talkinghead","Text-to-Speech","Token Counter","Use local of cloud-based Stable Diffusion webUI API to generate images. 5 presets included ('you', 'your face', 'me', 'the story', and 'the last message'. Free mode also supported via /sd (anything_here_) command in the chat input bar. Most common StableDiffusion generation settings are customizable within the SillyTavern UI.","What it doesn't do: Magically increase your context size. What it does: Optimizes the arrangement of your message history within the context space for more effective use. Imagine two variables: X: How many original chat messages to keep Y: Maximum number of ChromaDB 'memories' to inject When the chat reaches the threshold of X messages, additional messages will no longer be included in the context chronologically. Instead, they will be selected from the history based on their similarity to your recent inputs (limited to a maximum of Y), which should provide more relevant information than simply disregarding past messages. Adjust these values according to your average number of in-context entries for optimal performance."]}],[{"l":"Expression Images"},{"i":"what-is-it","l":"What is it?","p":["Expression images are images (aka 'sprites') of your AI character which are shown next to (or behind) the chat window.","Expression images do not require Extras to work.","However, having Extras running with the classify module enabled allows the Expressions to change automatically based on the sentiment expressed in the AI's most recent chat response."]},{"i":"setup-instructions-offline-mode-without-extras","l":"Setup Instructions (Offline Mode without Extras)","p":["Open the Extensions Panel and expand the 'Expression images' section (the section will only show up when you have a character selected). You will see a grid of image placeholders. Expression Drawer","Click the 'import' button at the top left of each image in the grid, and select the image you want to apply to that emotion. This will save the image with the correct filename inside the /public/characters/(character_name_here)/ folder.","To show the image in your SillyTavern window, click the image in the grid after it has been uploaded."]},{"i":"setup-instructions-with-extras","l":"Setup Instructions (with Extras)","p":["Have Extras installed and running with the classify module enabled: python server.py --enable-modules=classify","Import the expression images the same way as mentioned above.","The appropriate expression image will display automatically whenever the AI sends you a response."]},{"i":"how-do-i-get-more-expression-options","l":"How do I get more expression options?","p":["By default we use a classification model with 6 options nateraw/bert-base-uncased-emotion","There is also a model with 28 options: : joeddav/distilbert-base-uncased-go-emotions-student","To use this model you need to change your Extras command line to include the following argument (with a space before and after):","--classification-model=joeddav/distilbert-base-uncased-go-emotions-student"]},{"i":"how-does-the-classify-module-work","l":"How does the classify module work?","p":["The classify module uses a small 'sentiment parsing' model that runs on the SillyTavern Extras host machine (eg. on your PC, or on the colab machine). This model takes the new output from the AI and detects what kind of sentiment, or emotion, the text is expressing. While multiple sentiments may be expressed in a single message, the model only picks the most likely one and returns that back to the Extras server. The Extras server then displays the image that is associated with that sentiment."]},{"i":"what-image-formats-are-supported-for-expressions","l":"What image formats are supported for Expressions?","p":["Any image format is allowed, including webp and animated gifs.","The most common format is a PNG file with a transparent background."]},{"i":"using-the-default-expressions","l":"Using the 'default expressions'","p":["(This feature will only activate if Extras is running. There is no way to manually display default expression images.)","Use Default Expressions","If you don't have custom expression images for a character, you can use the built-in default expressions which are included with the base SillyTavern installation. These are simple emoji style images. Just click the checkbox at the bottom of the Expression images section inside the Extension panel. Default expressions will work alongside any available custom Expressions, and will display in cases when your custom image set is any missing images for a particular emotion."]},{"l":"Importing an Expression images zip file","p":["Using the 'import ZIP' button, you can import a zip file which contains a collection of expression images, and those images will automatically be added into the correct folder for your currently selected character. The zip file must have a flat internal structure (no subfolders) and the individual images should be named correctly. Importing a zip will not automatically rename any images to make them match the emotions."]},{"l":"Limitations"},{"i":"display-names-not-character-card-filenames-dictate-which-image-set-is-used","l":"Display names (not character card filenames) dictate which image set is used","p":["If you have more than one character with the same display name, they will both use the same set of expression images.","If you want a different image set to be used for each version of the same-named character, you must change the display name of one of them, and provide the alternate expression images in a folder with the new display name."]}],[{"l":"Objective"},{"i":"what-is-it","l":"What is it?","p":["The Objective extension lets the user specify an Objective for the AI to strive towards during the chat. This objective is broken down into step-by-step tasks. Tasks may be branched, where child tasks can be created automatically or manually. This gives the ability to create complex task trees. The completion status of each task in the list will be checked at certain intervals.","This differs from adding static direction through prompting in that it adds sequential and paced directives for the AI to follow without user intervention. It gives a more genuine experience of the AI autonomously striving to reach a goal."]},{"l":"Common Use Cases","p":["Your imagination is the limit, you can give the AI any objective you wish and it will plan out how to achieve it. You can ask it to plan how to slay a demon, rob a temple, throw a lavish party, or even take over the world.","Objective Settings Panel"]},{"l":"Configuration","p":["The extension is found in the Extensions menu under Objective.","Type an objective into the top text box, then click on Auto-Generate Tasks. This sends a request to the connected API and asks it to provide a list of tasks which match the objective you have typed in.","Note: Clicking Auto-Generate Tasks will delete all existing tasks for the currently selected Objective before adding new ones.","Upon receiving the response from the AI, a list of tasks will be created automatically in the space below the Objective input box. Tasks can be edited after creation.","At the bottom of the panel are two boxes: Position in Chat and Task Check Frequency","Position in Chat- This is how 'deep' in the chat section of the prompt you want the current task to be inserted. The lower the number, the more attention the AI will give to the task. Setting to 0 will make the task the primary thing in the AI's mind. Setting at high values will put the task in the background and allow the AI to focus on the conversation at hand, but setting it too high may cause the AI to never 'get around' to the task at all.","Task Check Frequency- This is how often you want the AI to check if the task has been completed. If it is set to 3, the AI will be asked if the current task has been completed every 3rd message.","Objectives, tasks, and their descriptions are saved in real-time to the current chat session. Custom prompts are saved globally."]},{"l":"Custom Prompts","p":["You can customize the prompts sent to the LLM to generate tasks, check task completion, and for prompt injection. Editing prompts will save them for the current session. Custom prompts can be saved and loaded for persistence.","Click Edit Prompts to open the prompt editor window. You can edit your prompts as desired.","To save prompts, enter a name and click Save Prompt.","To load prompts, select the prompt from the dropdown list.","To delete a saved prompt, select it from the dropdown list and click Delete Prompt","WARNING: Task Checking happens in a separate API request. Setting Task Check Frequency to 1 will double your API calls to the LLM service. Be careful with this if you are using a paid service."]},{"l":"Usage","p":["By default the Objective extension will keep track of all tasks and their respective completion status automatically.","The User can also manually create, update, delete, and complete tasks at any time."]},{"l":"Current Task Selection","p":["The current task will always be the first listed incomplete task. Any manual updates to tasks will trigger a check for what the current task should be. So if you add a task above a bunch of completed tasks, it will be set as the current task. Once it's completed, previously completed tasks will be skipped and the next incomplete task will be selected as 'Current'.","When using parent/child tasks in a task tree, tasks are selected depth-first, meaning all child tasks will be selected in order first, then continue down the list of tasks for the current Objective/Task."]},{"l":"Branch Tasks","p":["Click the Branch Task button to set the current task as an Objective where you can auto generate or manually create tasks as child tasks. You can continue to turn any child task into an Objective and keep generating to your hearts content.","Marking a parent task as complete will cause the extension to skip all subtasks. When all child tasks are complete, the parent task will be marked as complete"]},{"l":"Manually Complete Tasks","p":["You can manually toggle the completion status of a task by clicking the checkbox next to it. This will set the next incomplete task to be selected."]},{"l":"Manual Task Check","p":["If you want to manually trigger the AI to check for task completion, click on the Extras Extension button (the magic wand on the right side of the chat input bar) and select Manual Task Check."]},{"l":"Manually Add Tasks","p":["When no tasks are present, an Add Task button is visible, allowing you to manually create the first task.","If other tasks are already present, click the + button to the right of any task to insert a new task after it."]},{"l":"Delete Tasks","p":["Click the red x to delete an existing task. The next incomplete task will be selected as the current task automatically.","Deleting a task with child tasks will delete all child tasks and their descendants."]},{"l":"Hiding Tasks","p":["If you want to remain unaware of what tasks the AI is attempting to complete, check the Hide Tasks box to hide the task list and make the AI's intentions a mystery. For 100% mysteriousness, do this before clicking Auto-Generate Tasks!"]}],[{"l":"RVC","p":["RVC stands for Realtime Voice Cloning. This technique allows transferring voice features from one audio clip to another, essentially making it speak in a different voice.","Have you ever seen popular \"Presidents Play X\" videos? Yes, that was RVC too. You can make your SillyTavern characters speak any voice (anime/movie/your own) using the RVC Extra module."]},{"l":"RVC Setup","p":["PREREQUISITES:","sillytavern-extras: Switch to the neo branch","sillytavern: Switch to the staging branch","In a file browser navigate to \\SillyTavern-extras\\data\\models\\rvc, create a subfolder and put .pth and .index into the created folder","Install requirements with: pip install -r requirements-rvc.txt","Run SillyTavern-extras with an RVC module enabled (add other models and parameters if needed):","In SillyTavern, go to Extensions --> RVC and enable it","Setup a Voice map for RVC: read the instructions for TTS above, but instead of TTS voices, use RVC model folder names","Select pitch extraction: rmvpe","Go to Extensions --> TTS and enable it","Select TTS Provider: Coqui or your other preferred provider, but not System- RVC doesn't work with it. ElevenLabs is not recommended since it has its own voice cloning capabilities","Enable Auto Generation"]},{"l":"Train your own RVC model"},{"i":"rvc-easy-menu-by-deffcolony-only-for-windows","l":"RVC Easy Menu by Deffcolony (only for Windows).","p":["Automatically install and launch Mangio-RVC: https://github.com/deffcolony/rvc-easy-menu","Choose a location where you want to git clone the repo because RVC will install in the same location where you launch the script:","Open RVC-Launcher.bat","Choose 1 since you want to install RVC.","When 7-zip pops up just, click install because it's a requirement for the 7z package that will get extracted automatically.","After installation when the menu returns choose 2 to open WebUI for Voice Training."]},{"i":"mangio-rvc---train-a-voice-model","l":"Mangio-RVC - Train a voice model","p":["Dataset preparation:","Put the voice you want to train in the datasets folder.","Make sure there is NO BACKGROUND NOISE in the audio file; only raw voice!","The output quality will be better the longer the audio.","In the WebUI:","Click on the training tab","Enter the experiment name, for example, my-epic-voice-model","Set version to v2","Click on \"Process data\"","Click on \"Feature extraction\"","Set \"Save frequency\" to 50","Set \"Total training epochs\" to 300","Click on \"Train feature index\"","Click on \"Train model\""]}],[{"l":"Smart Context"},{"i":"what-is-it","l":"What is it?","p":["Smart Context is a SillyTavern extension that uses the ChromaDB library to give your AI characters access to information that exists outside the normal chat history context limit."]},{"i":"how-is-that-useful","l":"How is that useful?","p":["If you have a very long chat, the majority of the contents are outside the usual context window and thus unavailable to the AI when it comes to writing a response.","Smart Context automatically takes the entire history of the chat file and puts it into a vector database. This database is then searched each time you input something new into the chat, and if messages with matching keywords are found, those chat messages are placed into the context so the AI can see them when writing its next reply."]},{"l":"Setup Instructions","p":["Update SillyTavern to at least main branch version 1.6.0.","Install or Update Extras to the latest version.","Install requirements-complete.txt for Extras (even if you did it once before in a prior install).","run Extras with the chromadb module enabled: python server.py --enable-modules=chromadb"]},{"i":"getting-an-error-when-installing-chromadb","l":"Getting an error when installing ChromaDB?","p":["Installing chromadb package requires one of the following:","Have Visual C++ build tools installed: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Installing hnswlib from conda: conda install -c conda-forge hnswlib"]},{"l":"Configuration","p":["Once Smart Context is enabled, you should configure it in the SillyTavern UI. Smart Context configuration can be done from within the Extensions menu STExtensionMenuIcon","Smart Context Config Panel","There are 4 main concepts to be aware of:","Chat History Preservation","Memory Injection Amount","Individual Memory Length","Injection Strategy"]},{"l":"SmartContext only starts after 10 mesages are in the chat history","p":["At the start of a new chat, ChromaDB is inactive.","Once the chat has accumulated 10 messages, it will begin recording all messages into the database, and recalling messages as needed."]},{"i":"chat-history-preservation-kept-mesages","l":"Chat History Preservation ('kept mesages')","p":["By default, ChromaDB will keep as many recent natural chat history messages as specified in the slider. Any messages beyond this amount will be removed from your sent prompt, and if 'memories' exist in the database they will be added in place of the older chat history messages (see Strategy below)."]},{"l":"Memory Injection Amount","p":["The maximum number of 'memories' Smart Context will insert into the context. Not every injection attempt will get this full amount. If you send an input related to 'dogs' and only one other message in the DB is related to dogs, then only 1 item will be inserted."]},{"l":"Individual Memory Length","p":["This is the maximum length allowed for each injected 'memory'. This is in CHARACTERS(not tokens). If set too small, the memory could be cut off midway.","Example:","Ross: I like dogs with long fur and fluffy tails. I dislike dogs with short fur and short tails.","This database 'memory' is 103 characters long, so you would need to set the slider to at least 103 in order to pull it entirely into the context.","If the slider is less than 103, the message would be cut off and injected like that."]},{"l":"Injection Strategy"},{"l":"Replace oldest history","p":["This strategy keeps X recent messages, removes all message before that, and replaces them with 'memories'.","Advantage","less likely to overflow your context limit","memories existing near the top of the context will have less immediate impact on the response while still providing 'background information'.","Disadvantage","old messages are inserted directly into the chat history with no special demarcation, and usually have no immediate natural relevance to the preserved natural chat history messages. This can confuse less intelligent AI models."]},{"l":"Add to Bottom","p":["This strategy leaves the chat history in its natural state and adds 'memories' after it inside a formatted [bracket header]. This means the 'kept messages' sliders is effectively disabled.","Advantage","does not shorten or alter the current natural chat history","'memories' exist after chat and have a stronger impact on the next AI response","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit.","because the memories exist very close to the end of the prompt they can have TOO MUCH effect on the AI's response."]},{"l":"Custom Depth","p":["This strategy leaves the chat history in its natural state and adds 'memories' at the depth you determine within the template you specify. This means the 'kept messages' slider is effectively disabled. The custom injection message should include the `` template word which is where all queried memories will be placed.","Advantage","flexibility to experiment with memory placement","customizable introductions to memory within context","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit."]},{"i":"use--strategy","l":"Use % Strategy","p":["Note: This is not compatible with the 'Add to Bottom' strategy, which does not remove any messages at all.","While using the 'Replace Oldest History' strategy, checking this box will enable the slider for selecting a percentage of the in-context chat history to replace with SmartContext memories. It will also disable the two sliders for manually selecting the number of messages.","This strategy automatically calculates a percentage of the chat history to be replaced with SmartContext memories, instead of a fixed number of messages.","Advantage","easier than manually calculating the number of messages yourself","adjusts with the available context size, applying the same percentage to small and large prompt spaces","Disadvantage","calculations for how much history to remove can be slightly innacurate as they are based on estimated tokens per message","it rounds the number of messages to remove to the nearest number divisible by 5 (0, 5, 10, 15, 20, etc), so it is not as fine grained as manual numeric selection."]},{"l":"Memory Recall Strategy"},{"l":"Recall only from this chat","p":["This is the default behavior of smart-context and pulls 'memories' only from the ChromaDB collection for this specific chat."]},{"l":"Recall from all character chats","p":["This is an experimental behavior of smart-context which pulls 'memories' from all ChromaDB collections for the selected character. Hypothetically this should allow for the development of a more robust memory set spanning many interactions. Reccomended that this be used with 'Add to Bottom' or 'Custom Depth' strategies and 'kept messages' set to a low number so that ChromaDB will pull from memory sooner."]},{"l":"Using Smart Context","p":["Once it is enabled and configured, Smart Context happens automatically.","ChromaDB makes a new database for each chat that is opened inside SillyTavern. This database is automatically filled with the entire chat history.","You can also manually insert text files into the database.","These text files do not have to be chats. They can be anything (wikipedia entries, fanfic, etc)."]},{"l":"Purging the Database","p":["You can use the 'Purge DB' button to clear the database for the current chat.","This can be helpful if you find inaccurate memories have been stored (such as chat message you have since deleted or edited)."]},{"l":"FAQ"},{"i":"what-happens-to-the-databases-when-im-done-chatting-can-i-save-them","l":"What happens to the databases when I'm done chatting? Can I save them?","p":["For locally installed Extras servers, Smart Context saves the databases. There is no need to save them manually in usual use cases.","For colab users, the databases are wiped when the extras server shuts down. Use the export button to save the database as a JSON file, and import it next time you want to use it.","Usually there is no need to save Smart Context databases.","Currently we have an Import/Export feature, which allows you to save the chat's DB and use it again at a later date."]},{"i":"can-i-make-one-big-database-for-all-of-my-chats-to-reference","l":"Can I make one big database for all of my chats to reference?","p":["This would not be a good use of Smart Context's capabilities. We recommend using World Info for this purpose."]}],[{"l":"Summarize"},{"i":"what-is-it","l":"What is it?","p":["After the AI sends back a message, the Summarize extension looks through the chat history and then uses an AI summarization model that runs on the Extras host machine to create a dynamic summary of events. This summary is then sent along with every user input afterwards."]},{"i":"how-is-that-useful","l":"How is that useful?","p":["Summarize helps the AI remain aware of the general developments of a long chat."]},{"l":"Setup Instructions","p":["Summarize requires the Extras server to run. It has no offline mode.","Install or Update Extras to the latest version.","Run Extras with the summarize module enabled: python server.py --enable-modules=summarize"]},{"l":"Configuration","p":["Once Summarize is enabled, it will show up in ST's Extensions panel list. STExtensionMenuIcon","Summarize Config Panel","Summary Contents Box- this displays the current summary. Summary is updated and embedded into the chat file's metadata for every message recieved from the AI.","Restore Previous State- Replaces the current summaryt with the summary from the previous message. This is useful if the summarizer does a poor job at any given point.","Stop Summarization Updates checkbox- check this to prevent the summary from being automatically updated. This is useful if you want to provide a custom summary of your own, or to effectively disable the summary by clearing the box and stopping udpates.","Chat to Summarize buffer length- This is the amount of chat context to be summarized, including the previous message's sumnmary. Limited to 1024 tokens.","Summary Output Length- The desired total length of the finished summary (what you see in the box). The summary will not always match this length, but the model will be encouraged to write enough to fill it.","Temperature- determines how creative the summary model is in writing the summary. higher values will produce more variation in the summary, at potential risk of inaccuracy.","Repetition Penalty- high numbers here will help reduce the amount of repetitious phrases in the summary. 1.15-1.2 are good values.","Length Preference- values below 1 will pressure the AI to create shorter summarize, and values over 1 will encentive the AI to create longer summaries."]},{"l":"Changing Summary Model","p":["By default, Summarize uses the Qiliang/bart-large-cnn-samsum-ChatGPT_v3 model for summarization purposes.","This can be changed by using the command line argument --summarization-model=(###Hugging-Face-Model-URL-Here###)","A known alternate Summarize model is Qiliang/bart-large-cnn-samsum-ElectrifAi_v10."]},{"l":"Useage Notes","p":["Sumamry does not begin working until the chat has continued long enough that all chat messages are no longer able to fit into the context window.","Summaries are saved individually as metadata for each message in the chat file.","Deleting a message from the chat will effectively remove its summary as well."]}],[{"l":"talkinghead"},{"i":"what-is-it","l":"What is it?","p":["A implementation of Talking Head Anime 3 Demo for AITuber. It possesses the following features:","This extentsion contains the orginal demo programs for the Talking Head(?) Anime from a Single Image 3: Now the Body Too project. As the name implies, the project allows you to animate anime characters, and you only need a single image of that character to do so. There are two demo programs:","The manual_poser lets you manipulate a character's facial expression, head rotation, body rotation, and chest expansion due to breathing through a graphical user interface, so you can save them as default expressions IE Happy, sad, joy etc. ifacialmocap_puppeteer lets you transfer your facial motion to an anime character."]},{"l":"Hardware Requirements","p":["You can use either CPU or GPU Modes (CPU is default). However in CPU mode expect about 1 FPS and in GPU mode on an RTX3060 i am getting about 9-10 FPS.","The ifacialmocap_puppeteer requires an iOS device that is capable of computing blend shape parameters from a video feed. This means that the device must be able to run iOS 11.0 or higher and must have a TrueDepth front-facing camera. (See this page for more info.) In other words, if you have the iPhone X or something better, you should be all set."]},{"l":"How to use","p":["You must launch extras with the following modules for talkinghead to work: classify and talkinghead! classify is required for handling of the talkinghead.png file. Additionally you may also use --talkinghead-gpu to load the blend models into GPU memory and make the animations 10x faster. It is highly recommended to use gpu acceleration! By default once the program starts it will load a default image SillyTavern-extras\\talkinghead\\tha3\\images\\lambda_00.png. You can verify it is working by going to http://localhost:5100/api/talkinghead/result_feed or YOUR EXT URL:PORT/api/talkinghead/result_feed.","-Once the server has started goto the Extension API tab and connect. Then simply select a character card to load. (--enable-modules=classify,talkinghead --talkinghead-gpu in server.py)","-Now select the Character Expressions, if you check the image type talkinghead box the script will replace your current character expression with the result of YOUR EXT URL:PORT/api/talkinghead/result_feed unchecking the box SHOULD return the image back to the orginal expression, however sometimes you have to send a new message to the chat to \"reload\" the image.","-If you do not have a talkinghead.png file in the character directory it will simply show either the default image or the last character card that had a talkinghead.png file. The animation source image is changed when the character card is changed.","-Now open the character expressions scroll down to the talkinghead image and upload an image file that meets the requirements in the section below called \"Contraints on Input Images\".","-Then check and uncheck the talkinghead box to reload the character. IF the image is funny looking it is probably because it is not transparent / has no alpha layer. Otherwise follow the instructions and teamplate below."]},{"l":"Contraints on Input Images","p":["In order for the system to work well, the input image must obey the following constraints:","It should be of resolution 512 x 512. (If the program receives an input image of any other size, they will resize the image to this resolution and also output at this resolution.) It must have an alpha channel. It must contain only one humanoid character. The character should be standing upright and facing forward. The character's hands should be below and far from the head. The head of the character should roughly be contained in the 128 x 128 box in the middle of the top half of the image. The alpha channels of all pixels that do not belong to the character (i.e., background pixels) must be 0."]},{"l":"ADVANCED SECTION"},{"l":"Python Environment","p":["In addition to the base feature (app.py), both manual_poser and ifacialmocap_puppeteer are available as desktop applications. To run them, you need to set up an environment for running programs written in the Python language. The environment needs to have the following software packages:","Python >= 3.8 PyTorch >= 1.11.0 with CUDA support SciPY >= 1.7.3 wxPython >= 4.1.1 Matplotlib >= 3.5.1 One way to do so is to install Anaconda and run the following commands in your shell:","conda create -n talking-head-anime-3-demo python=3.8 conda activate talking-head-anime-3-demo conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch conda install scipy pip install wxpython conda install matplotlib"]},{"l":"Additional Blend Models","p":["There is only one (lightest) model included, if you want the additional blend models you need to download the model files from https://www.dropbox.com/s/y7b8jl4n2euv8xe/talking-head-anime-3-models.zip?dl=0 and unzip it to the SillyTavern-extras\\talkinghead\\tha3\\models folder. In the end, the data folder should look like:","tha3","models","separable_float","editor.pt","eyebrow_decomposer.pt","eyebrow_morphing_combiner.pt","face_morpher.pt","two_algo_face_body_rotator.pt","separable_half","editor.pt:","standard_float","standard_half","The model files are distributed with the Creative Commons Attribution 4.0 International License, which means that you can use them for commercial purposes. However, Pramook Khungurn. Talking Head(?) Anime from a Single Image 3: Now the Body Too. http://pkhungurn.github.io/talking-head-anime-3/, is the creator."]},{"l":"Running the manual_poser Desktop Application","p":["Open a shell. Change your working directory to the repository's root directory. Then, run:","python tha3/app/manual_poser.py Note that before running the command above, you might have to activate the Python environment that contains the required packages.","conda activate extras if you have not already activated the environment."]}],[{"l":"TTS","p":["SillyTavern has a wide range of TTS options. This page explains the setup and use."]},{"i":"what-is-it","l":"What is it?","p":["TTS is used to have a voice narrate parts of your chat."]},{"l":"Configuring TTS"},{"l":"TTS Provider Selectbox","p":["Used to select which TTS service you want to use.","ElevenLabs- paid subscription required, highest quality voices available at present.","Silero- free, runs on your PC, quality can vary widely","System- uses your OS TTS engine, if one exists. Quality can vary widely depending on the OS.","Edge- free, runs via Azure, generally quite fast, and voices feel natural but dry and emotionless. Like listening to the evening news or a radio announcer.","Coqui-TTS- free, No API Implementation at this time. High-performance Text2Speech models (Tacotron, Tacotron2, Glow-TTS, SpeedySpeech) as well as Bark.","Novel- requires a paid NovelAI subscription, generated by NovelAI's TTS engine","RVC- free, voice cloning"]},{"l":"Checkboxes","p":["\"Good evening, senpai\"","\"Good evening, senpai\", she says.","\"nya\"... \"Good evening, senpai\"","Auto Generation- lets TTS start playing automatically when a new message enters the chat","Cohee approaches you with a faint \"nya\" \"Good evening, senpai\", she says.","Disabled","Enabled","Enabled- turns TTS playback on/off","Given the example text: *Cohee approaches you with a faint nya* Good evening, senpai, she says. Here's a table showing how the text will be modified based on the boolean states of Ignore *text, even \"quotes\", inside asterisks* and Only narrate \"quotes\":","having both \"only narrate quotes\" and \"ignore asterisks\" checkboxes both checked will result in the TTS only reading \"quotes\" which are not in asterisks, and ignoring everything else.","Ignore *text, even \"quotes\", inside asterisks*","Ignore *text, even \"quotes\", inside asterisks*- TTS will not play any text within *asterisks*, even \"quotes\" (internal variable name = narrate_dialogues_only)","Narrate only the translated text- this will make the TTS only narrate the translated text.","Only narrate \"quotes\"","Only narrate \"quotes\"- Limits TTS playback to only include text within quotation marks. This will *include quotes within asterisk lines*(internal variable name = narrate_quoted_only)","Output"]},{"l":"Sliders","p":["These will change depending on the API you select.","(explanation coming soon)"]},{"l":"Buttons","p":["Apply- this must be clicked after setting a TTS API and after editing the voice map.","Available voices- loads a popup with all voices available for your selected API, and lets you preview them with sample dialogues."]},{"l":"Using TTS","p":["Click the \"Enable\" checkbox, or nothing will ever happen.","Click the \"Auto-generation\" checkbox if you want the TTS to start automatically every time a new message arrives in chat.","Optionally, click the megaphone icon inside the top-right of any message to playback on demand.","Click the lower right \"Stop\" button (found inside the wand menu) to stop any playback."]},{"l":"Voice Map","p":["You must provide a voice map for the TTS to use, otherwise, it won't know what voices should be used for each character.","These must be in the exact format stated below:","CharacterName:TTSVoice,CharacterName2:TTSVoice2","For Coqui-TTS the format needs to include the speaker and language from the WebGUI:","CharacterName:TTSVoice[speakerid][langid] or Aqua:tts_models--multilingual--multi-dataset--your_tts\\model_file.pth[2][1]"]},{"l":"Bark ZeroShot Voice Cloning Speakers","p":["If using Bark you must create a voice folder with a voice file to clone. Ensure you add voices to homedir\\tts\\bark_v0\\speakers. On Windows it is probably C:\\Users\\USERACCOUNT\\AppData\\Local\\tts\\bark_v0\\speakers\\ type %appdata% in windows explorer then go UP a directory to local and you should see tts.","The directory should look like this:","homedir","tts","bark_v0","speakers","customvoice1","speaker.wav","speaker.npz","robinwilliams","speaker.mp3","me","One first load of this model and voice bark will clone the voice and create a .npz file, this is needed for faster TTS."]}],[{"l":"Writing Extensions","p":["Plugins extend the functionality of SillyTavern by hooking into its events and API. You can easily create your own extensions."]},{"i":"manifestjson","l":"manifest.json","p":["Every extension must have a folder in public/scripts/extensions and have a manifest.json file which contains metadata about the plugin and a JS script file.","The display_name, js and author fields are required."]},{"l":"Using getContext","p":["The getContext() function gives you access to the SillyTavern context:","Use this to interact with the main app state."]},{"l":"Importing from other files","p":["You can import variables and functions from other JS files.","For example, this code snipped will generate a reply from the currently selected API in a background:"]},{"l":"Registering slash commands","p":["Use registerSlashCommand() to register a new slash command:"]},{"l":"Listening for event types","p":["Use eventSource.on() to listen for events:","Main event types are:","MESSAGE_RECEIVED","MESSAGE_SENT","CHAT_CHANGED"]},{"l":"Do Extras request","p":["The doExtrasFetch() function allows you to make requests to your SillyTavern Extra server.","For example, to call the /api/summarize endpoint:","getApiUrl() returns the base URL of the Extras serve.","The doExtrasFetch() function:","Adds the Authorization and Bypass-Tunnel-Reminder headers","Handles fetching the result","Returns the result (the response object)","This makes it easy to call your Extra's API from your plugin.","You can specify:","The request method: GET, POST, etc.","Additional headers","The body for POST requests","And any other fetch options"]}],[{"l":"License and credits","p":["AI Horde client library by ZeldaFan0225: https://github.com/ZeldaFan0225/ai_horde","Cohee's modifications and derived code: AGPL v3","Icon theme by Font Awesome https://fontawesome.com(Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License)","kingbri's various commits and suggestions ( https://github.com/bdashore3)","KoboldAI Presets from KAI Lite: https://lite.koboldai.net/","Linux startup script by AlpinDale","Noto Sans font by Google (OFL license)","Portions of CncAnon's TavernAITurbo mod: Unknown license","RossAscends' additions: AGPL v3","See the GNU Affero General Public License for more details.","TAI Base by Humi: Unknown license","Thanks paniphons for providing a FAQ document","Thanks to oobabooga for compiling presets for TextGen","Thanks to Pygmalion University for being awesome testers and suggesting cool features!","This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.","TTS and Objective extensions by Ouoertheo","Waifu Mode inspired by the work of PepperTaco ( https://github.com/peppertaco/Tavern/)"]},{"i":"feel-your-name-is-missing-here","l":"Feel your name is missing here?","p":["Open a Pull Request by using the \"Edit this page\" link so we could properly credit you and your contributions!"]}]]